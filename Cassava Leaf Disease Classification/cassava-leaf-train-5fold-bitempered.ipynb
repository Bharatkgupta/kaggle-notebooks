{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:18.263255Z",
     "iopub.status.busy": "2021-02-11T13:36:18.262526Z",
     "iopub.status.idle": "2021-02-11T13:36:36.930893Z",
     "shell.execute_reply": "2021-02-11T13:36:36.931426Z"
    },
    "papermill": {
     "duration": 18.683306,
     "end_time": "2021-02-11T13:36:36.931784",
     "exception": false,
     "start_time": "2021-02-11T13:36:18.248478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet /kaggle/input/kerasapplications\n",
    "!pip install --quiet /kaggle/input/efficientnet-keras-source-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:36.962152Z",
     "iopub.status.busy": "2021-02-11T13:36:36.961429Z",
     "iopub.status.idle": "2021-02-11T13:36:43.959726Z",
     "shell.execute_reply": "2021-02-11T13:36:43.958951Z"
    },
    "papermill": {
     "duration": 7.016141,
     "end_time": "2021-02-11T13:36:43.959877",
     "exception": false,
     "start_time": "2021-02-11T13:36:36.943736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math, os, random, re, gc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "import efficientnet.tfkeras as efn\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:43.994113Z",
     "iopub.status.busy": "2021-02-11T13:36:43.993130Z",
     "iopub.status.idle": "2021-02-11T13:36:49.943619Z",
     "shell.execute_reply": "2021-02-11T13:36:49.942941Z"
    },
    "papermill": {
     "duration": 5.97242,
     "end_time": "2021-02-11T13:36:49.943769",
     "exception": false,
     "start_time": "2021-02-11T13:36:43.971349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:49.984976Z",
     "iopub.status.busy": "2021-02-11T13:36:49.984258Z",
     "iopub.status.idle": "2021-02-11T13:36:50.392890Z",
     "shell.execute_reply": "2021-02-11T13:36:50.392215Z"
    },
    "papermill": {
     "duration": 0.437747,
     "end_time": "2021-02-11T13:36:50.393081",
     "exception": false,
     "start_time": "2021-02-11T13:36:49.955334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-tfrecords-512x512')\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "EPOCHS = 30\n",
    "SEED = 42\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.432955Z",
     "iopub.status.busy": "2021-02-11T13:36:50.427672Z",
     "iopub.status.idle": "2021-02-11T13:36:50.444659Z",
     "shell.execute_reply": "2021-02-11T13:36:50.443995Z"
    },
    "papermill": {
     "duration": 0.039715,
     "end_time": "2021-02-11T13:36:50.444803",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.405088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bi-temperedloss\n",
    "\n",
    "def log_t(u, t):\n",
    "  \"\"\"Compute log_t for `u`.\"\"\"\n",
    "  if t == 1.0:\n",
    "    return tf.math.log(u)\n",
    "  else:\n",
    "    return (u**(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "  \"\"\"Compute exp_t for `u`.\"\"\"\n",
    "  if t == 1.0:\n",
    "    return tf.math.exp(u)\n",
    "  else:\n",
    "    return tf.math.maximum(0.0, 1.0 + (1.0 - t) * u) ** (1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(y_pred, t, num_iters=5):\n",
    "  \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "    y_pred: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as y_pred with the last dimension being 1.\n",
    "  \"\"\"\n",
    "  mu = tf.math.reduce_max(y_pred, -1, keepdims=True)\n",
    "  normalized_y_pred_step_0 = y_pred - mu\n",
    "  normalized_y_pred = normalized_y_pred_step_0\n",
    "  i = 0\n",
    "  while i < num_iters:\n",
    "    i += 1\n",
    "    logt_partition = tf.math.reduce_sum(exp_t(normalized_y_pred, t),-1, keepdims=True)\n",
    "    normalized_y_pred = normalized_y_pred_step_0 * (logt_partition ** (1.0 - t))\n",
    "  \n",
    "  logt_partition = tf.math.reduce_sum(exp_t(normalized_y_pred, t), -1, keepdims=True)\n",
    "  return -log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "def compute_normalization(y_pred, t, num_iters=5):\n",
    "  \"\"\"Returns the normalization value for each example.\n",
    "    Args:\n",
    "    y_pred: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature 2 (< 1.0 for finite support, > 1.0 for tail heaviness).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "  \"\"\"\n",
    "  if t < 1.0:\n",
    "    return None # not implemented as these values do not occur in the authors experiments...\n",
    "  else:\n",
    "    return compute_normalization_fixed_point(y_pred, t, num_iters)\n",
    "\n",
    "def tempered_softmax(y_pred, t, num_iters=5):\n",
    "  \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "    y_pred: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature tensor > 0.0.\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "    A probabilities tensor.\n",
    "  \"\"\"\n",
    "  if t == 1.0:\n",
    "    normalization_constants = tf.math.log(tf.math.reduce_sum(tf.math.exp(y_pred), -1, keepdims=True))\n",
    "  else:\n",
    "    normalization_constants = compute_normalization(y_pred, t, num_iters)\n",
    "\n",
    "  return exp_t(y_pred - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_logistic_loss(y_pred, y_true, t1, t2, num_iters=5, label_smoothing=0.0):\n",
    "  \"\"\"Bi-Tempered Logistic Loss with custom gradient.\n",
    "    Args:\n",
    "    y_pred: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    y_true: A tensor with shape and dtype as y_pred.\n",
    "    t1: Temperature 1 (< 1.0 for boundedness).\n",
    "    t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "    A loss tensor.\n",
    "  \"\"\"\n",
    "  y_pred = tf.cast(y_pred, tf.float32)\n",
    "  y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "  if label_smoothing > 0.0:\n",
    "    num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "    y_true = (1 - num_classes /(num_classes - 1) * label_smoothing) * y_true + label_smoothing / (num_classes - 1)\n",
    "\n",
    "  probabilities = tempered_softmax(y_pred, t2, num_iters)\n",
    "\n",
    "  temp1 = (log_t(y_true + 1e-10, t1) - log_t(probabilities, t1)) * y_true\n",
    "  temp2 = (1 / (2 - t1)) * (tf.math.pow(y_true, 2 - t1) - tf.math.pow(probabilities, 2 - t1))\n",
    "  loss_values = temp1 - temp2\n",
    "\n",
    "  return tf.math.reduce_sum(loss_values, -1)\n",
    "\n",
    "class BiTemperedLogisticLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self, t1, t2, n_iter=5, label_smoothing=0.0):\n",
    "    super(BiTemperedLogisticLoss, self).__init__()\n",
    "    self.t1 = t1\n",
    "    self.t2 = t2\n",
    "    self.n_iter = n_iter\n",
    "    self.label_smoothing = label_smoothing\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    return bi_tempered_logistic_loss(y_pred, y_true, self.t1, self.t2, self.n_iter, self.label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.495225Z",
     "iopub.status.busy": "2021-02-11T13:36:50.487073Z",
     "iopub.status.idle": "2021-02-11T13:36:50.498207Z",
     "shell.execute_reply": "2021-02-11T13:36:50.497505Z"
    },
    "papermill": {
     "duration": 0.041878,
     "end_time": "2021-02-11T13:36:50.498352",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.456474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform_mat(image, DIM=IMAGE_SIZE[0]):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 \n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "    \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d, [DIM, DIM,3])\n",
    "\n",
    "def dropout(image, DIM=IMAGE_SIZE[0], PROBABILITY = 0.5, CT = 4, SZ = 0.1):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image with CT squares of side size SZ*DIM removed\n",
    "    \n",
    "    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "    if (P==0)|(CT==0)|(SZ==0): return image\n",
    "    \n",
    "    for k in range(CT):\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        # COMPUTE SQUARE \n",
    "        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # DROPOUT IMAGE\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3]) \n",
    "        three = image[ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n",
    "    image = tf.reshape(image,[DIM,DIM,3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.551722Z",
     "iopub.status.busy": "2021-02-11T13:36:50.547758Z",
     "iopub.status.idle": "2021-02-11T13:36:50.555892Z",
     "shell.execute_reply": "2021-02-11T13:36:50.554937Z"
    },
    "papermill": {
     "duration": 0.045756,
     "end_time": "2021-02-11T13:36:50.556042",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.510286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onehot(image,label):\n",
    "    return image,tf.one_hot(label,len(CLASSES))\n",
    "\n",
    "\n",
    "def cutmix(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
    "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j,ya:yb,0:xa,:]\n",
    "        two = image[k,ya:yb,xa:xb,:]\n",
    "        three = image[j,ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def mixup(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with mixup applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
    "        # CHOOSE RANDOM\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n",
    "        # MAKE MIXUP IMAGE\n",
    "        img1 = image[j,]\n",
    "        img2 = image[k,]\n",
    "        imgs.append((1-a)*img1 + a*img2)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "        \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def transform(image,label):\n",
    "    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    SWITCH = 0.5\n",
    "    CUTMIX_PROB = 0.666\n",
    "    MIXUP_PROB = 0.666\n",
    "    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n",
    "    image1 = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        img = transform_mat(image[j,])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        image1.append(img)\n",
    "        \n",
    "    image1 = tf.reshape(tf.stack(image1),(AUG_BATCH,DIM,DIM,3))\n",
    "    image2, label2 = cutmix(image1, label, CUTMIX_PROB)\n",
    "    image3, label3 = mixup(image1, label, MIXUP_PROB)\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n",
    "        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n",
    "        labs.append(P*label2[j,]+(1-P)*label3[j,])\n",
    "    \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image4,label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.591946Z",
     "iopub.status.busy": "2021-02-11T13:36:50.591240Z",
     "iopub.status.idle": "2021-02-11T13:36:50.594394Z",
     "shell.execute_reply": "2021-02-11T13:36:50.593786Z"
    },
    "papermill": {
     "duration": 0.026456,
     "end_time": "2021-02-11T13:36:50.594527",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.568071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0     ###\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.622204Z",
     "iopub.status.busy": "2021-02-11T13:36:50.621463Z",
     "iopub.status.idle": "2021-02-11T13:36:50.631995Z",
     "shell.execute_reply": "2021-02-11T13:36:50.631421Z"
    },
    "papermill": {
     "duration": 0.02535,
     "end_time": "2021-02-11T13:36:50.632164",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.606814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.3)\n",
    "    image = dropout(image)\n",
    "    return image, label\n",
    "\n",
    "def get_training_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048, seed = SEED)\n",
    "    dataset = dataset.batch(AUG_BATCH)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.665157Z",
     "iopub.status.busy": "2021-02-11T13:36:50.664077Z",
     "iopub.status.idle": "2021-02-11T13:36:50.666882Z",
     "shell.execute_reply": "2021-02-11T13:36:50.667339Z"
    },
    "papermill": {
     "duration": 0.023098,
     "end_time": "2021-02-11T13:36:50.667512",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.644414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=BATCH_SIZE):\n",
    "    lr_start   = 0.00000001\n",
    "    lr_max     = 0.0000000250 * strategy.num_replicas_in_sync * batch_size\n",
    "    lr_min     = 0.00000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.85\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:36:50.703691Z",
     "iopub.status.busy": "2021-02-11T13:36:50.702909Z",
     "iopub.status.idle": "2021-02-11T13:37:15.807717Z",
     "shell.execute_reply": "2021-02-11T13:37:15.806883Z"
    },
    "papermill": {
     "duration": 25.12804,
     "end_time": "2021-02-11T13:37:15.807896",
     "exception": false,
     "start_time": "2021-02-11T13:36:50.679856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
      "71680000/71678424 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b4 (Functional) (None, 16, 16, 1792)      17673816  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 8965      \n",
      "=================================================================\n",
      "Total params: 17,682,781\n",
      "Trainable params: 17,432,381\n",
      "Non-trainable params: 250,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    with strategy.scope():       \n",
    "        input_layer = tf.keras.layers.Input(shape=(512,512,3))\n",
    "        base = efn.EfficientNetB4(input_shape=(512,512,3),weights='noisy-student',include_top=False)\n",
    "        base.trainable = True\n",
    "        \n",
    "        for layer in base.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable =  False\n",
    "        \n",
    "        x = base(input_layer)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        output_layer = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "        loss = BiTemperedLogisticLoss(t1 = 0.4, t2 = 2, label_smoothing=0.0001)\n",
    "        \n",
    "        model.compile(optimizer=opt,loss=loss,metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:37:15.854442Z",
     "iopub.status.busy": "2021-02-11T13:37:15.853768Z",
     "iopub.status.idle": "2021-02-11T13:37:15.959052Z",
     "shell.execute_reply": "2021-02-11T13:37:15.958416Z"
    },
    "papermill": {
     "duration": 0.130458,
     "end_time": "2021-02-11T13:37:15.959212",
     "exception": false,
     "start_time": "2021-02-11T13:37:15.828754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/Id_train*.tfrec\")\n",
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T13:37:16.012746Z",
     "iopub.status.busy": "2021-02-11T13:37:16.012035Z",
     "iopub.status.idle": "2021-02-11T17:01:49.879388Z",
     "shell.execute_reply": "2021-02-11T17:01:49.880152Z"
    },
    "papermill": {
     "duration": 12273.901742,
     "end_time": "2021-02-11T17:01:49.880437",
     "exception": false,
     "start_time": "2021-02-11T13:37:15.978695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD-1\n",
      "\n",
      "Epoch 1/30\n",
      "267/267 [==============================] - 162s 358ms/step - loss: 0.5541 - categorical_accuracy: 0.1497 - val_loss: 0.6480 - val_categorical_accuracy: 0.1094\n",
      "Epoch 2/30\n",
      "267/267 [==============================] - 73s 273ms/step - loss: 0.5348 - categorical_accuracy: 0.4988 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 3/30\n",
      "267/267 [==============================] - 84s 313ms/step - loss: 0.5217 - categorical_accuracy: 0.6162 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 4/30\n",
      "267/267 [==============================] - 71s 264ms/step - loss: 0.5203 - categorical_accuracy: 0.6149 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 5/30\n",
      "267/267 [==============================] - 74s 278ms/step - loss: 0.5199 - categorical_accuracy: 0.6247 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 6/30\n",
      "267/267 [==============================] - 82s 306ms/step - loss: 0.5202 - categorical_accuracy: 0.6175 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 7/30\n",
      "267/267 [==============================] - 70s 264ms/step - loss: 0.5189 - categorical_accuracy: 0.6109 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 8/30\n",
      "267/267 [==============================] - 67s 252ms/step - loss: 0.5212 - categorical_accuracy: 0.6217 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 9/30\n",
      "267/267 [==============================] - 73s 274ms/step - loss: 0.5193 - categorical_accuracy: 0.6105 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 10/30\n",
      "267/267 [==============================] - 76s 283ms/step - loss: 0.5200 - categorical_accuracy: 0.6154 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 11/30\n",
      "267/267 [==============================] - 89s 335ms/step - loss: 0.5199 - categorical_accuracy: 0.6130 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 12/30\n",
      "267/267 [==============================] - 74s 276ms/step - loss: 0.5201 - categorical_accuracy: 0.6131 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 13/30\n",
      "267/267 [==============================] - 74s 276ms/step - loss: 0.5196 - categorical_accuracy: 0.6037 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 14/30\n",
      "267/267 [==============================] - 89s 333ms/step - loss: 0.5185 - categorical_accuracy: 0.6191 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 15/30\n",
      "267/267 [==============================] - 70s 262ms/step - loss: 0.5213 - categorical_accuracy: 0.6181 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 16/30\n",
      "267/267 [==============================] - 75s 282ms/step - loss: 0.5196 - categorical_accuracy: 0.6128 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 17/30\n",
      "267/267 [==============================] - 83s 310ms/step - loss: 0.5204 - categorical_accuracy: 0.6174 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 18/30\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.5210 - categorical_accuracy: 0.6092 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 19/30\n",
      "267/267 [==============================] - 69s 257ms/step - loss: 0.5205 - categorical_accuracy: 0.6279 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 20/30\n",
      "267/267 [==============================] - 74s 277ms/step - loss: 0.5194 - categorical_accuracy: 0.6145 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 21/30\n",
      "267/267 [==============================] - 77s 287ms/step - loss: 0.5203 - categorical_accuracy: 0.6018 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 22/30\n",
      "267/267 [==============================] - 91s 340ms/step - loss: 0.5192 - categorical_accuracy: 0.6288 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 23/30\n",
      "267/267 [==============================] - 74s 276ms/step - loss: 0.5195 - categorical_accuracy: 0.6174 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 24/30\n",
      "267/267 [==============================] - 81s 304ms/step - loss: 0.5195 - categorical_accuracy: 0.6191 - val_loss: 0.6117 - val_categorical_accuracy: 0.6148\n",
      "Epoch 25/30\n",
      "267/267 [==============================] - 72s 271ms/step - loss: 0.5178 - categorical_accuracy: 0.6122 - val_loss: 0.6116 - val_categorical_accuracy: 0.6148\n",
      "Epoch 26/30\n",
      "267/267 [==============================] - 67s 250ms/step - loss: 0.5222 - categorical_accuracy: 0.6165 - val_loss: 0.6115 - val_categorical_accuracy: 0.6148\n",
      "Epoch 27/30\n",
      "267/267 [==============================] - 66s 249ms/step - loss: 0.5205 - categorical_accuracy: 0.6117 - val_loss: 0.6114 - val_categorical_accuracy: 0.6153\n",
      "Epoch 28/30\n",
      "267/267 [==============================] - 71s 267ms/step - loss: 0.5192 - categorical_accuracy: 0.6168 - val_loss: 0.6112 - val_categorical_accuracy: 0.6165\n",
      "Epoch 29/30\n",
      "267/267 [==============================] - 77s 290ms/step - loss: 0.5199 - categorical_accuracy: 0.6120 - val_loss: 0.6111 - val_categorical_accuracy: 0.6170\n",
      "Epoch 30/30\n",
      "267/267 [==============================] - 67s 253ms/step - loss: 0.5207 - categorical_accuracy: 0.6162 - val_loss: 0.6109 - val_categorical_accuracy: 0.6191\n",
      "FOLD-2\n",
      "\n",
      "Epoch 1/30\n",
      "267/267 [==============================] - 178s 415ms/step - loss: 0.5484 - categorical_accuracy: 0.4045 - val_loss: 0.6437 - val_categorical_accuracy: 0.3300\n",
      "Epoch 2/30\n",
      "267/267 [==============================] - 86s 323ms/step - loss: 0.5323 - categorical_accuracy: 0.5941 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 3/30\n",
      "267/267 [==============================] - 79s 295ms/step - loss: 0.5214 - categorical_accuracy: 0.6028 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 4/30\n",
      "267/267 [==============================] - 88s 330ms/step - loss: 0.5185 - categorical_accuracy: 0.6028 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 5/30\n",
      "267/267 [==============================] - 72s 271ms/step - loss: 0.5190 - categorical_accuracy: 0.6154 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 6/30\n",
      "267/267 [==============================] - 77s 288ms/step - loss: 0.5211 - categorical_accuracy: 0.6167 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 7/30\n",
      "267/267 [==============================] - 84s 316ms/step - loss: 0.5198 - categorical_accuracy: 0.6124 - val_loss: 0.6118 - val_categorical_accuracy: 0.6139\n",
      "Epoch 8/30\n",
      "267/267 [==============================] - 70s 264ms/step - loss: 0.5191 - categorical_accuracy: 0.6160 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 9/30\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.5206 - categorical_accuracy: 0.6177 - val_loss: 0.6116 - val_categorical_accuracy: 0.6162\n",
      "Epoch 10/30\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.5199 - categorical_accuracy: 0.6029 - val_loss: 0.6115 - val_categorical_accuracy: 0.6170\n",
      "Epoch 11/30\n",
      "267/267 [==============================] - 88s 331ms/step - loss: 0.5198 - categorical_accuracy: 0.6067 - val_loss: 0.6114 - val_categorical_accuracy: 0.6170\n",
      "Epoch 12/30\n",
      "267/267 [==============================] - 78s 291ms/step - loss: 0.5208 - categorical_accuracy: 0.6203 - val_loss: 0.6097 - val_categorical_accuracy: 0.6397\n",
      "Epoch 13/30\n",
      "267/267 [==============================] - 78s 294ms/step - loss: 0.5184 - categorical_accuracy: 0.6304 - val_loss: 0.6052 - val_categorical_accuracy: 0.7005\n",
      "Epoch 14/30\n",
      "267/267 [==============================] - 74s 278ms/step - loss: 0.5167 - categorical_accuracy: 0.6512 - val_loss: 0.6023 - val_categorical_accuracy: 0.7330\n",
      "Epoch 15/30\n",
      "267/267 [==============================] - 62s 233ms/step - loss: 0.5178 - categorical_accuracy: 0.6706 - val_loss: 0.6030 - val_categorical_accuracy: 0.7221\n",
      "Epoch 16/30\n",
      "267/267 [==============================] - 73s 273ms/step - loss: 0.5146 - categorical_accuracy: 0.6827 - val_loss: 0.6014 - val_categorical_accuracy: 0.7401\n",
      "Epoch 17/30\n",
      "267/267 [==============================] - 91s 341ms/step - loss: 0.5138 - categorical_accuracy: 0.6869 - val_loss: 0.6012 - val_categorical_accuracy: 0.7431\n",
      "Epoch 18/30\n",
      "267/267 [==============================] - 71s 265ms/step - loss: 0.5161 - categorical_accuracy: 0.6961 - val_loss: 0.6009 - val_categorical_accuracy: 0.7479\n",
      "Epoch 19/30\n",
      "267/267 [==============================] - 82s 308ms/step - loss: 0.5155 - categorical_accuracy: 0.6930 - val_loss: 0.6010 - val_categorical_accuracy: 0.7462\n",
      "Epoch 20/30\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.5145 - categorical_accuracy: 0.6956 - val_loss: 0.6010 - val_categorical_accuracy: 0.7457\n",
      "Epoch 21/30\n",
      "267/267 [==============================] - 74s 277ms/step - loss: 0.5137 - categorical_accuracy: 0.6890 - val_loss: 0.6005 - val_categorical_accuracy: 0.7509\n",
      "Epoch 22/30\n",
      "267/267 [==============================] - 67s 249ms/step - loss: 0.5140 - categorical_accuracy: 0.6955 - val_loss: 0.6003 - val_categorical_accuracy: 0.7524\n",
      "Epoch 23/30\n",
      "267/267 [==============================] - 84s 317ms/step - loss: 0.5151 - categorical_accuracy: 0.6935 - val_loss: 0.6006 - val_categorical_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "267/267 [==============================] - 70s 264ms/step - loss: 0.5146 - categorical_accuracy: 0.7032 - val_loss: 0.6001 - val_categorical_accuracy: 0.7557\n",
      "Epoch 25/30\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.5147 - categorical_accuracy: 0.6994 - val_loss: 0.6000 - val_categorical_accuracy: 0.7554\n",
      "Epoch 26/30\n",
      "267/267 [==============================] - 81s 306ms/step - loss: 0.5148 - categorical_accuracy: 0.7032 - val_loss: 0.6002 - val_categorical_accuracy: 0.7517\n",
      "Epoch 27/30\n",
      "267/267 [==============================] - 70s 262ms/step - loss: 0.5138 - categorical_accuracy: 0.7051 - val_loss: 0.6001 - val_categorical_accuracy: 0.7543\n",
      "Epoch 28/30\n",
      "267/267 [==============================] - 66s 249ms/step - loss: 0.5146 - categorical_accuracy: 0.6985 - val_loss: 0.6000 - val_categorical_accuracy: 0.7552\n",
      "Epoch 29/30\n",
      "267/267 [==============================] - 64s 241ms/step - loss: 0.5146 - categorical_accuracy: 0.7029 - val_loss: 0.5999 - val_categorical_accuracy: 0.7571\n",
      "Epoch 30/30\n",
      "267/267 [==============================] - 67s 252ms/step - loss: 0.5132 - categorical_accuracy: 0.6924 - val_loss: 0.5999 - val_categorical_accuracy: 0.7588\n",
      "FOLD-3\n",
      "\n",
      "Epoch 1/30\n",
      "267/267 [==============================] - 184s 429ms/step - loss: 0.5513 - categorical_accuracy: 0.3374 - val_loss: 0.6425 - val_categorical_accuracy: 0.4787\n",
      "Epoch 2/30\n",
      "267/267 [==============================] - 84s 313ms/step - loss: 0.5313 - categorical_accuracy: 0.5848 - val_loss: 0.6118 - val_categorical_accuracy: 0.6141\n",
      "Epoch 3/30\n",
      "267/267 [==============================] - 77s 289ms/step - loss: 0.5190 - categorical_accuracy: 0.6131 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 4/30\n",
      "267/267 [==============================] - 86s 323ms/step - loss: 0.5196 - categorical_accuracy: 0.6208 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 5/30\n",
      "267/267 [==============================] - 71s 265ms/step - loss: 0.5167 - categorical_accuracy: 0.6062 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 6/30\n",
      "267/267 [==============================] - 74s 275ms/step - loss: 0.5186 - categorical_accuracy: 0.6093 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 7/30\n",
      "267/267 [==============================] - 76s 284ms/step - loss: 0.5219 - categorical_accuracy: 0.6133 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 8/30\n",
      "267/267 [==============================] - 91s 341ms/step - loss: 0.5203 - categorical_accuracy: 0.6220 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 9/30\n",
      "267/267 [==============================] - 75s 281ms/step - loss: 0.5193 - categorical_accuracy: 0.6135 - val_loss: 0.6117 - val_categorical_accuracy: 0.6141\n",
      "Epoch 10/30\n",
      "267/267 [==============================] - 77s 290ms/step - loss: 0.5219 - categorical_accuracy: 0.6146 - val_loss: 0.6117 - val_categorical_accuracy: 0.6143\n",
      "Epoch 11/30\n",
      "267/267 [==============================] - 88s 330ms/step - loss: 0.5194 - categorical_accuracy: 0.6216 - val_loss: 0.6116 - val_categorical_accuracy: 0.6146\n",
      "Epoch 12/30\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.5200 - categorical_accuracy: 0.6080 - val_loss: 0.6093 - val_categorical_accuracy: 0.6463\n",
      "Epoch 13/30\n",
      "267/267 [==============================] - 79s 298ms/step - loss: 0.5180 - categorical_accuracy: 0.6406 - val_loss: 0.6057 - val_categorical_accuracy: 0.6911\n",
      "Epoch 14/30\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.5124 - categorical_accuracy: 0.6540 - val_loss: 0.6033 - val_categorical_accuracy: 0.7192\n",
      "Epoch 15/30\n",
      "267/267 [==============================] - 63s 235ms/step - loss: 0.5152 - categorical_accuracy: 0.6679 - val_loss: 0.6016 - val_categorical_accuracy: 0.7431\n",
      "Epoch 16/30\n",
      "267/267 [==============================] - 67s 252ms/step - loss: 0.5129 - categorical_accuracy: 0.6864 - val_loss: 0.6010 - val_categorical_accuracy: 0.7474\n",
      "Epoch 17/30\n",
      "267/267 [==============================] - 86s 321ms/step - loss: 0.5135 - categorical_accuracy: 0.6938 - val_loss: 0.6009 - val_categorical_accuracy: 0.7462\n",
      "Epoch 18/30\n",
      "267/267 [==============================] - 75s 282ms/step - loss: 0.5129 - categorical_accuracy: 0.7027 - val_loss: 0.6004 - val_categorical_accuracy: 0.7512\n",
      "Epoch 19/30\n",
      "267/267 [==============================] - 68s 256ms/step - loss: 0.5155 - categorical_accuracy: 0.7024 - val_loss: 0.6001 - val_categorical_accuracy: 0.7543\n",
      "Epoch 20/30\n",
      "267/267 [==============================] - 84s 316ms/step - loss: 0.5142 - categorical_accuracy: 0.7078 - val_loss: 0.6001 - val_categorical_accuracy: 0.7545\n",
      "Epoch 21/30\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.5137 - categorical_accuracy: 0.7005 - val_loss: 0.5998 - val_categorical_accuracy: 0.7599\n",
      "Epoch 22/30\n",
      "267/267 [==============================] - 68s 256ms/step - loss: 0.5106 - categorical_accuracy: 0.7043 - val_loss: 0.5997 - val_categorical_accuracy: 0.7614\n",
      "Epoch 23/30\n",
      "267/267 [==============================] - 85s 319ms/step - loss: 0.5111 - categorical_accuracy: 0.6984 - val_loss: 0.5997 - val_categorical_accuracy: 0.7609\n",
      "Epoch 24/30\n",
      "267/267 [==============================] - 72s 269ms/step - loss: 0.5118 - categorical_accuracy: 0.7007 - val_loss: 0.5996 - val_categorical_accuracy: 0.7633\n",
      "Epoch 25/30\n",
      "267/267 [==============================] - 68s 255ms/step - loss: 0.5125 - categorical_accuracy: 0.7096 - val_loss: 0.5996 - val_categorical_accuracy: 0.7640\n",
      "Epoch 26/30\n",
      "267/267 [==============================] - 81s 305ms/step - loss: 0.5098 - categorical_accuracy: 0.7069 - val_loss: 0.5994 - val_categorical_accuracy: 0.7640\n",
      "Epoch 27/30\n",
      "267/267 [==============================] - 68s 253ms/step - loss: 0.5130 - categorical_accuracy: 0.7136 - val_loss: 0.5994 - val_categorical_accuracy: 0.7652\n",
      "Epoch 28/30\n",
      "267/267 [==============================] - 67s 249ms/step - loss: 0.5139 - categorical_accuracy: 0.7051 - val_loss: 0.5994 - val_categorical_accuracy: 0.7642\n",
      "Epoch 29/30\n",
      "267/267 [==============================] - 74s 277ms/step - loss: 0.5128 - categorical_accuracy: 0.7165 - val_loss: 0.5994 - val_categorical_accuracy: 0.7666\n",
      "Epoch 30/30\n",
      "267/267 [==============================] - 86s 321ms/step - loss: 0.5133 - categorical_accuracy: 0.7024 - val_loss: 0.5994 - val_categorical_accuracy: 0.7654\n",
      "FOLD-4\n",
      "\n",
      "Epoch 1/30\n",
      "267/267 [==============================] - 174s 394ms/step - loss: 0.5488 - categorical_accuracy: 0.3099 - val_loss: 0.6431 - val_categorical_accuracy: 0.4747\n",
      "Epoch 2/30\n",
      "267/267 [==============================] - 80s 298ms/step - loss: 0.5335 - categorical_accuracy: 0.5775 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 3/30\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.5197 - categorical_accuracy: 0.6108 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 4/30\n",
      "267/267 [==============================] - 72s 270ms/step - loss: 0.5207 - categorical_accuracy: 0.6146 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 5/30\n",
      "267/267 [==============================] - 73s 273ms/step - loss: 0.5182 - categorical_accuracy: 0.6119 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 6/30\n",
      "267/267 [==============================] - 86s 323ms/step - loss: 0.5190 - categorical_accuracy: 0.6239 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 7/30\n",
      "267/267 [==============================] - 68s 256ms/step - loss: 0.5213 - categorical_accuracy: 0.6220 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 8/30\n",
      "267/267 [==============================] - 72s 270ms/step - loss: 0.5201 - categorical_accuracy: 0.6194 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 9/30\n",
      "267/267 [==============================] - 73s 275ms/step - loss: 0.5185 - categorical_accuracy: 0.6149 - val_loss: 0.6114 - val_categorical_accuracy: 0.6174\n",
      "Epoch 10/30\n",
      "267/267 [==============================] - 84s 314ms/step - loss: 0.5201 - categorical_accuracy: 0.6300 - val_loss: 0.6078 - val_categorical_accuracy: 0.6617\n",
      "Epoch 11/30\n",
      "267/267 [==============================] - 65s 245ms/step - loss: 0.5158 - categorical_accuracy: 0.6375 - val_loss: 0.6050 - val_categorical_accuracy: 0.6951\n",
      "Epoch 12/30\n",
      "267/267 [==============================] - 67s 253ms/step - loss: 0.5160 - categorical_accuracy: 0.6620 - val_loss: 0.6053 - val_categorical_accuracy: 0.6899\n",
      "Epoch 13/30\n",
      "267/267 [==============================] - 84s 317ms/step - loss: 0.5185 - categorical_accuracy: 0.6679 - val_loss: 0.6017 - val_categorical_accuracy: 0.7356\n",
      "Epoch 14/30\n",
      "267/267 [==============================] - 65s 244ms/step - loss: 0.5162 - categorical_accuracy: 0.6868 - val_loss: 0.6004 - val_categorical_accuracy: 0.7514\n",
      "Epoch 15/30\n",
      "267/267 [==============================] - 65s 243ms/step - loss: 0.5171 - categorical_accuracy: 0.6980 - val_loss: 0.5999 - val_categorical_accuracy: 0.7571\n",
      "Epoch 16/30\n",
      "267/267 [==============================] - 66s 248ms/step - loss: 0.5134 - categorical_accuracy: 0.7002 - val_loss: 0.6000 - val_categorical_accuracy: 0.7557\n",
      "Epoch 17/30\n",
      "267/267 [==============================] - 87s 326ms/step - loss: 0.5159 - categorical_accuracy: 0.7053 - val_loss: 0.5993 - val_categorical_accuracy: 0.7640\n",
      "Epoch 18/30\n",
      "267/267 [==============================] - 64s 241ms/step - loss: 0.5123 - categorical_accuracy: 0.6985 - val_loss: 0.5996 - val_categorical_accuracy: 0.7588\n",
      "Epoch 19/30\n",
      "267/267 [==============================] - 71s 266ms/step - loss: 0.5130 - categorical_accuracy: 0.7020 - val_loss: 0.5997 - val_categorical_accuracy: 0.7597\n",
      "Epoch 20/30\n",
      "267/267 [==============================] - 74s 278ms/step - loss: 0.5157 - categorical_accuracy: 0.7006 - val_loss: 0.5992 - val_categorical_accuracy: 0.7656\n",
      "Epoch 21/30\n",
      "267/267 [==============================] - 85s 317ms/step - loss: 0.5151 - categorical_accuracy: 0.7126 - val_loss: 0.5994 - val_categorical_accuracy: 0.7607\n",
      "Epoch 22/30\n",
      "267/267 [==============================] - 70s 263ms/step - loss: 0.5133 - categorical_accuracy: 0.7109 - val_loss: 0.5994 - val_categorical_accuracy: 0.7611\n",
      "Epoch 23/30\n",
      "267/267 [==============================] - 75s 279ms/step - loss: 0.5130 - categorical_accuracy: 0.7087 - val_loss: 0.5991 - val_categorical_accuracy: 0.7640\n",
      "Epoch 24/30\n",
      "267/267 [==============================] - 82s 308ms/step - loss: 0.5138 - categorical_accuracy: 0.7089 - val_loss: 0.5990 - val_categorical_accuracy: 0.7673\n",
      "Epoch 25/30\n",
      "267/267 [==============================] - 67s 253ms/step - loss: 0.5123 - categorical_accuracy: 0.7071 - val_loss: 0.5990 - val_categorical_accuracy: 0.7668\n",
      "Epoch 26/30\n",
      "267/267 [==============================] - 66s 246ms/step - loss: 0.5127 - categorical_accuracy: 0.7098 - val_loss: 0.5993 - val_categorical_accuracy: 0.7625\n",
      "Epoch 27/30\n",
      "267/267 [==============================] - 69s 257ms/step - loss: 0.5129 - categorical_accuracy: 0.7085 - val_loss: 0.5989 - val_categorical_accuracy: 0.7668\n",
      "Epoch 28/30\n",
      "267/267 [==============================] - 73s 272ms/step - loss: 0.5126 - categorical_accuracy: 0.7073 - val_loss: 0.5991 - val_categorical_accuracy: 0.7649\n",
      "Epoch 29/30\n",
      "267/267 [==============================] - 86s 322ms/step - loss: 0.5147 - categorical_accuracy: 0.7163 - val_loss: 0.5989 - val_categorical_accuracy: 0.7668\n",
      "Epoch 30/30\n",
      "267/267 [==============================] - 67s 252ms/step - loss: 0.5133 - categorical_accuracy: 0.7095 - val_loss: 0.5990 - val_categorical_accuracy: 0.7673\n",
      "FOLD-5\n",
      "\n",
      "Epoch 1/30\n",
      "267/267 [==============================] - 172s 392ms/step - loss: 0.5559 - categorical_accuracy: 0.1136 - val_loss: 0.6457 - val_categorical_accuracy: 0.1406\n",
      "Epoch 2/30\n",
      "267/267 [==============================] - 79s 298ms/step - loss: 0.5379 - categorical_accuracy: 0.4904 - val_loss: 0.6117 - val_categorical_accuracy: 0.6158\n",
      "Epoch 3/30\n",
      "267/267 [==============================] - 73s 275ms/step - loss: 0.5209 - categorical_accuracy: 0.6204 - val_loss: 0.6116 - val_categorical_accuracy: 0.6158\n",
      "Epoch 4/30\n",
      "267/267 [==============================] - 73s 273ms/step - loss: 0.5193 - categorical_accuracy: 0.6114 - val_loss: 0.6116 - val_categorical_accuracy: 0.6158\n",
      "Epoch 5/30\n",
      "267/267 [==============================] - 75s 279ms/step - loss: 0.5195 - categorical_accuracy: 0.6126 - val_loss: 0.6115 - val_categorical_accuracy: 0.6172\n",
      "Epoch 6/30\n",
      "267/267 [==============================] - 85s 319ms/step - loss: 0.5205 - categorical_accuracy: 0.6279 - val_loss: 0.6027 - val_categorical_accuracy: 0.7251\n",
      "Epoch 7/30\n",
      "267/267 [==============================] - 65s 245ms/step - loss: 0.5147 - categorical_accuracy: 0.6848 - val_loss: 0.6010 - val_categorical_accuracy: 0.7427\n",
      "Epoch 8/30\n",
      "267/267 [==============================] - 66s 246ms/step - loss: 0.5149 - categorical_accuracy: 0.7087 - val_loss: 0.6001 - val_categorical_accuracy: 0.7533\n",
      "Epoch 9/30\n",
      "267/267 [==============================] - 81s 304ms/step - loss: 0.5103 - categorical_accuracy: 0.7072 - val_loss: 0.5992 - val_categorical_accuracy: 0.7642\n",
      "Epoch 10/30\n",
      "267/267 [==============================] - 63s 237ms/step - loss: 0.5142 - categorical_accuracy: 0.7145 - val_loss: 0.5992 - val_categorical_accuracy: 0.7647\n",
      "Epoch 11/30\n",
      "267/267 [==============================] - 67s 250ms/step - loss: 0.5108 - categorical_accuracy: 0.7281 - val_loss: 0.5989 - val_categorical_accuracy: 0.7682\n",
      "Epoch 12/30\n",
      "267/267 [==============================] - 73s 275ms/step - loss: 0.5120 - categorical_accuracy: 0.7201 - val_loss: 0.5989 - val_categorical_accuracy: 0.7673\n",
      "Epoch 13/30\n",
      "267/267 [==============================] - 73s 275ms/step - loss: 0.5133 - categorical_accuracy: 0.7315 - val_loss: 0.5987 - val_categorical_accuracy: 0.7687\n",
      "Epoch 14/30\n",
      "267/267 [==============================] - 71s 264ms/step - loss: 0.5125 - categorical_accuracy: 0.7155 - val_loss: 0.5988 - val_categorical_accuracy: 0.7682\n",
      "Epoch 15/30\n",
      "267/267 [==============================] - 68s 256ms/step - loss: 0.5108 - categorical_accuracy: 0.7198 - val_loss: 0.5985 - val_categorical_accuracy: 0.7739\n",
      "Epoch 16/30\n",
      "267/267 [==============================] - 62s 234ms/step - loss: 0.5130 - categorical_accuracy: 0.7275 - val_loss: 0.5984 - val_categorical_accuracy: 0.7737\n",
      "Epoch 17/30\n",
      "267/267 [==============================] - 58s 216ms/step - loss: 0.5129 - categorical_accuracy: 0.7263 - val_loss: 0.5985 - val_categorical_accuracy: 0.7718\n",
      "Epoch 18/30\n",
      "267/267 [==============================] - 64s 241ms/step - loss: 0.5141 - categorical_accuracy: 0.7310 - val_loss: 0.5985 - val_categorical_accuracy: 0.7732\n",
      "Epoch 19/30\n",
      "267/267 [==============================] - 87s 326ms/step - loss: 0.5099 - categorical_accuracy: 0.7332 - val_loss: 0.5983 - val_categorical_accuracy: 0.7753\n",
      "Epoch 20/30\n",
      "267/267 [==============================] - 65s 242ms/step - loss: 0.5138 - categorical_accuracy: 0.7362 - val_loss: 0.5983 - val_categorical_accuracy: 0.7758\n",
      "Epoch 21/30\n",
      "267/267 [==============================] - 61s 229ms/step - loss: 0.5109 - categorical_accuracy: 0.7280 - val_loss: 0.5983 - val_categorical_accuracy: 0.7756\n",
      "Epoch 22/30\n",
      "267/267 [==============================] - 73s 272ms/step - loss: 0.5124 - categorical_accuracy: 0.7334 - val_loss: 0.5982 - val_categorical_accuracy: 0.7753\n",
      "Epoch 23/30\n",
      "267/267 [==============================] - 87s 326ms/step - loss: 0.5096 - categorical_accuracy: 0.7283 - val_loss: 0.5983 - val_categorical_accuracy: 0.7751\n",
      "Epoch 24/30\n",
      "267/267 [==============================] - 71s 266ms/step - loss: 0.5106 - categorical_accuracy: 0.7311 - val_loss: 0.5982 - val_categorical_accuracy: 0.7770\n",
      "Epoch 25/30\n",
      "267/267 [==============================] - 66s 248ms/step - loss: 0.5114 - categorical_accuracy: 0.7267 - val_loss: 0.5982 - val_categorical_accuracy: 0.7749\n",
      "Epoch 26/30\n",
      "267/267 [==============================] - 78s 293ms/step - loss: 0.5130 - categorical_accuracy: 0.7307 - val_loss: 0.5982 - val_categorical_accuracy: 0.7763\n",
      "Epoch 27/30\n",
      "267/267 [==============================] - 75s 280ms/step - loss: 0.5140 - categorical_accuracy: 0.7333 - val_loss: 0.5982 - val_categorical_accuracy: 0.7768\n",
      "Epoch 28/30\n",
      "267/267 [==============================] - 73s 272ms/step - loss: 0.5109 - categorical_accuracy: 0.7410 - val_loss: 0.5982 - val_categorical_accuracy: 0.7758\n",
      "Epoch 29/30\n",
      "267/267 [==============================] - 71s 266ms/step - loss: 0.5121 - categorical_accuracy: 0.7295 - val_loss: 0.5982 - val_categorical_accuracy: 0.7756\n",
      "Epoch 30/30\n",
      "267/267 [==============================] - 65s 243ms/step - loss: 0.5119 - categorical_accuracy: 0.7341 - val_loss: 0.5982 - val_categorical_accuracy: 0.7765\n"
     ]
    }
   ],
   "source": [
    "for f, (trn_ind, val_ind) in enumerate(skf.split(TRAINING_FILENAMES)):\n",
    "    print(\"FOLD-{}\".format(f+1))\n",
    "    print()\n",
    "    \n",
    "    TRAIN_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[trn_ind]['TRAINING_FILENAMES'])\n",
    "    VALID_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[val_ind]['TRAINING_FILENAMES'])\n",
    "\n",
    "    train_dataset = get_training_dataset(TRAIN_FILENAMES)\n",
    "    valid_dataset = get_validation_dataset(VALID_FILENAMES)\n",
    "    \n",
    "    NUM_TRAINING_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
    "    NUM_VALID_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "    \n",
    "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "    VALID_STEPS = NUM_VALID_IMAGES // BATCH_SIZE\n",
    "    \n",
    "    CP = tf.keras.callbacks.ModelCheckpoint(\"5fold_model-{}.h5\".format(f+1),\n",
    "                                            monitor='val_categorical_accuracy', verbose=0, save_best_only=True,\n",
    "                                            save_weights_only=False, mode='max', save_freq='epoch')\n",
    "    \n",
    "    model = get_model()\n",
    "    history = model.fit(train_dataset, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=VALID_STEPS,\n",
    "                        callbacks = [get_lr_callback(BATCH_SIZE), CP])\n",
    "    \n",
    "    del model; z = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 12.342823,
     "end_time": "2021-02-11T17:02:14.724340",
     "exception": false,
     "start_time": "2021-02-11T17:02:02.381517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12379.65987,
   "end_time": "2021-02-11T17:02:31.713190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-11T13:36:12.053320",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
