{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:12:43.639966Z",
     "iopub.status.busy": "2021-02-16T06:12:43.628687Z",
     "iopub.status.idle": "2021-02-16T06:13:01.828452Z",
     "shell.execute_reply": "2021-02-16T06:13:01.827734Z"
    },
    "papermill": {
     "duration": 18.217143,
     "end_time": "2021-02-16T06:13:01.828672",
     "exception": false,
     "start_time": "2021-02-16T06:12:43.611529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet /kaggle/input/kerasapplications\n",
    "!pip install --quiet /kaggle/input/efficientnet-keras-source-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:01.858436Z",
     "iopub.status.busy": "2021-02-16T06:13:01.857406Z",
     "iopub.status.idle": "2021-02-16T06:13:08.674561Z",
     "shell.execute_reply": "2021-02-16T06:13:08.673938Z"
    },
    "papermill": {
     "duration": 6.834139,
     "end_time": "2021-02-16T06:13:08.674738",
     "exception": false,
     "start_time": "2021-02-16T06:13:01.840599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math, os, random, re, gc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "import efficientnet.tfkeras as efn\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:08.763017Z",
     "iopub.status.busy": "2021-02-16T06:13:08.761832Z",
     "iopub.status.idle": "2021-02-16T06:13:14.427685Z",
     "shell.execute_reply": "2021-02-16T06:13:14.428182Z"
    },
    "papermill": {
     "duration": 5.742459,
     "end_time": "2021-02-16T06:13:14.428365",
     "exception": false,
     "start_time": "2021-02-16T06:13:08.685906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:14.466672Z",
     "iopub.status.busy": "2021-02-16T06:13:14.465958Z",
     "iopub.status.idle": "2021-02-16T06:13:14.855650Z",
     "shell.execute_reply": "2021-02-16T06:13:14.856271Z"
    },
    "papermill": {
     "duration": 0.417233,
     "end_time": "2021-02-16T06:13:14.856478",
     "exception": false,
     "start_time": "2021-02-16T06:13:14.439245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-plant-disease-merged-20192020')\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "EPOCHS = 25\n",
    "SEED = 42\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:14.882192Z",
     "iopub.status.busy": "2021-02-16T06:13:14.881449Z",
     "iopub.status.idle": "2021-02-16T06:13:14.907983Z",
     "shell.execute_reply": "2021-02-16T06:13:14.908514Z"
    },
    "papermill": {
     "duration": 0.041181,
     "end_time": "2021-02-16T06:13:14.908705",
     "exception": false,
     "start_time": "2021-02-16T06:13:14.867524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform_mat(image, DIM=IMAGE_SIZE[0]):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 \n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "    \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d, [DIM, DIM,3])\n",
    "\n",
    "def dropout(image, DIM=IMAGE_SIZE[0], PROBABILITY = 0.5, CT = 4, SZ = 0.1):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image with CT squares of side size SZ*DIM removed\n",
    "    \n",
    "    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "    if (P==0)|(CT==0)|(SZ==0): return image\n",
    "    \n",
    "    for k in range(CT):\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        # COMPUTE SQUARE \n",
    "        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # DROPOUT IMAGE\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3]) \n",
    "        three = image[ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n",
    "    image = tf.reshape(image,[DIM,DIM,3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:14.961674Z",
     "iopub.status.busy": "2021-02-16T06:13:14.960924Z",
     "iopub.status.idle": "2021-02-16T06:13:14.963752Z",
     "shell.execute_reply": "2021-02-16T06:13:14.964274Z"
    },
    "papermill": {
     "duration": 0.044689,
     "end_time": "2021-02-16T06:13:14.964470",
     "exception": false,
     "start_time": "2021-02-16T06:13:14.919781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onehot(image,label):\n",
    "    return image,tf.one_hot(label,len(CLASSES))\n",
    "\n",
    "\n",
    "def cutmix(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
    "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j,ya:yb,0:xa,:]\n",
    "        two = image[k,ya:yb,xa:xb,:]\n",
    "        three = image[j,ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def mixup(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with mixup applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
    "        # CHOOSE RANDOM\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n",
    "        # MAKE MIXUP IMAGE\n",
    "        img1 = image[j,]\n",
    "        img2 = image[k,]\n",
    "        imgs.append((1-a)*img1 + a*img2)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "        \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def transform(image,label):\n",
    "    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    SWITCH = 0.8\n",
    "    CUTMIX_PROB = 0.666\n",
    "    MIXUP_PROB = 0.666\n",
    "    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n",
    "    image1 = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        img = transform_mat(image[j,])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        image1.append(img)\n",
    "        \n",
    "    image1 = tf.reshape(tf.stack(image1),(AUG_BATCH,DIM,DIM,3))\n",
    "    image2, label2 = cutmix(image1, label, CUTMIX_PROB)\n",
    "    image3, label3 = mixup(image1, label, MIXUP_PROB)\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n",
    "        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n",
    "        labs.append(P*label2[j,]+(1-P)*label3[j,])\n",
    "    \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image4,label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:14.999231Z",
     "iopub.status.busy": "2021-02-16T06:13:14.998142Z",
     "iopub.status.idle": "2021-02-16T06:13:15.001732Z",
     "shell.execute_reply": "2021-02-16T06:13:15.001185Z"
    },
    "papermill": {
     "duration": 0.026054,
     "end_time": "2021-02-16T06:13:15.001879",
     "exception": false,
     "start_time": "2021-02-16T06:13:14.975825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0     ###\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:15.035212Z",
     "iopub.status.busy": "2021-02-16T06:13:15.034195Z",
     "iopub.status.idle": "2021-02-16T06:13:15.037570Z",
     "shell.execute_reply": "2021-02-16T06:13:15.036915Z"
    },
    "papermill": {
     "duration": 0.024451,
     "end_time": "2021-02-16T06:13:15.037711",
     "exception": false,
     "start_time": "2021-02-16T06:13:15.013260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.3)\n",
    "    image = dropout(image)\n",
    "    return image, label\n",
    "\n",
    "def get_training_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048, seed = SEED)\n",
    "    dataset = dataset.batch(AUG_BATCH)\n",
    "    dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:15.068736Z",
     "iopub.status.busy": "2021-02-16T06:13:15.067809Z",
     "iopub.status.idle": "2021-02-16T06:13:15.071613Z",
     "shell.execute_reply": "2021-02-16T06:13:15.070960Z"
    },
    "papermill": {
     "duration": 0.022368,
     "end_time": "2021-02-16T06:13:15.071760",
     "exception": false,
     "start_time": "2021-02-16T06:13:15.049392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=BATCH_SIZE):\n",
    "    lr_start   = 0.0000001\n",
    "    lr_max     = 0.000000250 * strategy.num_replicas_in_sync * batch_size\n",
    "    lr_min     = 0.0000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.82\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:13:15.107275Z",
     "iopub.status.busy": "2021-02-16T06:13:15.106510Z",
     "iopub.status.idle": "2021-02-16T06:15:24.338068Z",
     "shell.execute_reply": "2021-02-16T06:15:24.339061Z"
    },
    "papermill": {
     "duration": 129.255873,
     "end_time": "2021-02-16T06:15:24.339391",
     "exception": false,
     "start_time": "2021-02-16T06:13:15.083518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b2_noisy-student_notop.h5\n",
      "31784960/31782304 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b2 (Functional) (None, 16, 16, 1408)      7768562   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 7045      \n",
      "=================================================================\n",
      "Total params: 7,775,607\n",
      "Trainable params: 7,640,471\n",
      "Non-trainable params: 135,136\n",
      "_________________________________________________________________\n",
      "None\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_noisy-student_notop.h5\n",
      "43933696/43933088 [==============================] - 1s 0us/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b3 (Functional) (None, 16, 16, 1536)      10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 7685      \n",
      "=================================================================\n",
      "Total params: 10,791,213\n",
      "Trainable params: 10,616,621\n",
      "Non-trainable params: 174,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
      "71680000/71678424 [==============================] - 1s 0us/step\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b4 (Functional) (None, 16, 16, 1792)      17673816  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 8965      \n",
      "=================================================================\n",
      "Total params: 17,682,781\n",
      "Trainable params: 17,432,381\n",
      "Non-trainable params: 250,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_noisy-student_notop.h5\n",
      "115261440/115255328 [==============================] - 1s 0us/step\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b5 (Functional) (None, 16, 16, 2048)      28513520  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 28,523,765\n",
      "Trainable params: 28,178,293\n",
      "Non-trainable params: 345,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b6_noisy-student_notop.h5\n",
      "165232640/165226952 [==============================] - 2s 0us/step\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b6 (Functional) (None, 16, 16, 2304)      40960136  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 11525     \n",
      "=================================================================\n",
      "Total params: 40,971,661\n",
      "Trainable params: 40,522,797\n",
      "Non-trainable params: 448,864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mlst = {\n",
    "    1: efn.EfficientNetB2,\n",
    "    2: efn.EfficientNetB3,\n",
    "    3: efn.EfficientNetB4,\n",
    "    4: efn.EfficientNetB5,\n",
    "    5: efn.EfficientNetB6\n",
    "}\n",
    "\n",
    "\n",
    "def get_model(f):\n",
    "    with strategy.scope():       \n",
    "        input_layer = tf.keras.layers.Input(shape=(512,512,3))\n",
    "        base = mlst[f](input_shape=(512,512,3),weights='noisy-student',include_top=False)\n",
    "        base.trainable = True\n",
    "        \n",
    "        for layer in base.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable =  False\n",
    "        \n",
    "        x = base(input_layer)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        output_layer = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=False,\n",
    "            label_smoothing=0.2,\n",
    "            name='categorical_crossentropy')\n",
    "        \n",
    "        model.compile(optimizer=opt,loss=loss,metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "for i in range(1,6):\n",
    "    model = get_model(i)\n",
    "    print(model.summary())\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T06:15:24.444176Z",
     "iopub.status.busy": "2021-02-16T06:15:24.443502Z",
     "iopub.status.idle": "2021-02-16T06:15:24.532078Z",
     "shell.execute_reply": "2021-02-16T06:15:24.531535Z"
    },
    "papermill": {
     "duration": 0.145615,
     "end_time": "2021-02-16T06:15:24.532269",
     "exception": false,
     "start_time": "2021-02-16T06:15:24.386654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/train_images_tfrecords/train-*.tfrec\")\n",
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T06:15:24.656547Z",
     "iopub.status.busy": "2021-02-16T06:15:24.655481Z",
     "iopub.status.idle": "2021-02-16T09:53:18.276269Z",
     "shell.execute_reply": "2021-02-16T09:53:18.275573Z"
    },
    "papermill": {
     "duration": 13073.696459,
     "end_time": "2021-02-16T09:53:18.276429",
     "exception": false,
     "start_time": "2021-02-16T06:15:24.579970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD-1\n",
      "\n",
      "Epoch 1/25\n",
      "328/328 [==============================] - 175s 392ms/step - loss: 1.6464 - categorical_accuracy: 0.1896 - val_loss: 1.5836 - val_categorical_accuracy: 0.2928\n",
      "Epoch 2/25\n",
      "328/328 [==============================] - 95s 291ms/step - loss: 1.3115 - categorical_accuracy: 0.6009 - val_loss: 0.9955 - val_categorical_accuracy: 0.8021\n",
      "Epoch 3/25\n",
      "328/328 [==============================] - 90s 275ms/step - loss: 1.1274 - categorical_accuracy: 0.7258 - val_loss: 0.9242 - val_categorical_accuracy: 0.8439\n",
      "Epoch 4/25\n",
      "328/328 [==============================] - 84s 257ms/step - loss: 1.0782 - categorical_accuracy: 0.7596 - val_loss: 0.8889 - val_categorical_accuracy: 0.8595\n",
      "Epoch 5/25\n",
      "328/328 [==============================] - 90s 275ms/step - loss: 1.0562 - categorical_accuracy: 0.7765 - val_loss: 0.8774 - val_categorical_accuracy: 0.8716\n",
      "Epoch 6/25\n",
      "328/328 [==============================] - 85s 260ms/step - loss: 1.0496 - categorical_accuracy: 0.7775 - val_loss: 0.8821 - val_categorical_accuracy: 0.8728\n",
      "Epoch 7/25\n",
      "328/328 [==============================] - 92s 280ms/step - loss: 1.0237 - categorical_accuracy: 0.7880 - val_loss: 0.8894 - val_categorical_accuracy: 0.8639\n",
      "Epoch 8/25\n",
      "328/328 [==============================] - 85s 260ms/step - loss: 1.0234 - categorical_accuracy: 0.7879 - val_loss: 0.8524 - val_categorical_accuracy: 0.8837\n",
      "Epoch 9/25\n",
      "328/328 [==============================] - 94s 287ms/step - loss: 1.0148 - categorical_accuracy: 0.7941 - val_loss: 0.8469 - val_categorical_accuracy: 0.8893\n",
      "Epoch 10/25\n",
      "328/328 [==============================] - 84s 256ms/step - loss: 1.0088 - categorical_accuracy: 0.7972 - val_loss: 0.8552 - val_categorical_accuracy: 0.8816\n",
      "Epoch 11/25\n",
      "328/328 [==============================] - 98s 300ms/step - loss: 1.0036 - categorical_accuracy: 0.8039 - val_loss: 0.8549 - val_categorical_accuracy: 0.8817\n",
      "Epoch 12/25\n",
      "328/328 [==============================] - 89s 272ms/step - loss: 1.0002 - categorical_accuracy: 0.8062 - val_loss: 0.8414 - val_categorical_accuracy: 0.8900\n",
      "Epoch 13/25\n",
      "328/328 [==============================] - 85s 258ms/step - loss: 0.9965 - categorical_accuracy: 0.8041 - val_loss: 0.8489 - val_categorical_accuracy: 0.8856\n",
      "Epoch 14/25\n",
      "328/328 [==============================] - 93s 285ms/step - loss: 0.9937 - categorical_accuracy: 0.8073 - val_loss: 0.8387 - val_categorical_accuracy: 0.8916\n",
      "Epoch 15/25\n",
      "328/328 [==============================] - 85s 258ms/step - loss: 0.9856 - categorical_accuracy: 0.8109 - val_loss: 0.8399 - val_categorical_accuracy: 0.8906\n",
      "Epoch 16/25\n",
      "328/328 [==============================] - 91s 276ms/step - loss: 0.9905 - categorical_accuracy: 0.8092 - val_loss: 0.8477 - val_categorical_accuracy: 0.8824\n",
      "Epoch 17/25\n",
      "328/328 [==============================] - 89s 272ms/step - loss: 0.9807 - categorical_accuracy: 0.8160 - val_loss: 0.8378 - val_categorical_accuracy: 0.8900\n",
      "Epoch 18/25\n",
      "328/328 [==============================] - 91s 278ms/step - loss: 0.9839 - categorical_accuracy: 0.8136 - val_loss: 0.8445 - val_categorical_accuracy: 0.8876\n",
      "Epoch 19/25\n",
      "328/328 [==============================] - 88s 268ms/step - loss: 0.9799 - categorical_accuracy: 0.8189 - val_loss: 0.8389 - val_categorical_accuracy: 0.8888\n",
      "Epoch 20/25\n",
      "328/328 [==============================] - 96s 292ms/step - loss: 0.9864 - categorical_accuracy: 0.8147 - val_loss: 0.8382 - val_categorical_accuracy: 0.8921\n",
      "Epoch 21/25\n",
      "328/328 [==============================] - 87s 264ms/step - loss: 0.9829 - categorical_accuracy: 0.8164 - val_loss: 0.8368 - val_categorical_accuracy: 0.8908\n",
      "Epoch 22/25\n",
      "328/328 [==============================] - 103s 315ms/step - loss: 0.9844 - categorical_accuracy: 0.8099 - val_loss: 0.8390 - val_categorical_accuracy: 0.8893\n",
      "Epoch 23/25\n",
      "328/328 [==============================] - 93s 284ms/step - loss: 0.9811 - categorical_accuracy: 0.8217 - val_loss: 0.8408 - val_categorical_accuracy: 0.8889\n",
      "Epoch 24/25\n",
      "328/328 [==============================] - 85s 260ms/step - loss: 0.9789 - categorical_accuracy: 0.8175 - val_loss: 0.8386 - val_categorical_accuracy: 0.8894\n",
      "Epoch 25/25\n",
      "328/328 [==============================] - 96s 294ms/step - loss: 0.9777 - categorical_accuracy: 0.8209 - val_loss: 0.8393 - val_categorical_accuracy: 0.8894\n",
      "\n",
      "FOLD-2\n",
      "\n",
      "Epoch 1/25\n",
      "328/328 [==============================] - 164s 332ms/step - loss: 1.6297 - categorical_accuracy: 0.2336 - val_loss: 1.5098 - val_categorical_accuracy: 0.4168\n",
      "Epoch 2/25\n",
      "328/328 [==============================] - 95s 291ms/step - loss: 1.3004 - categorical_accuracy: 0.6097 - val_loss: 0.9817 - val_categorical_accuracy: 0.8031\n",
      "Epoch 3/25\n",
      "328/328 [==============================] - 87s 266ms/step - loss: 1.1260 - categorical_accuracy: 0.7260 - val_loss: 0.9047 - val_categorical_accuracy: 0.8530\n",
      "Epoch 4/25\n",
      "328/328 [==============================] - 95s 290ms/step - loss: 1.0694 - categorical_accuracy: 0.7627 - val_loss: 0.8892 - val_categorical_accuracy: 0.8654\n",
      "Epoch 5/25\n",
      "328/328 [==============================] - 83s 254ms/step - loss: 1.0440 - categorical_accuracy: 0.7850 - val_loss: 0.8852 - val_categorical_accuracy: 0.8585\n",
      "Epoch 6/25\n",
      "328/328 [==============================] - 97s 295ms/step - loss: 1.0465 - categorical_accuracy: 0.7786 - val_loss: 0.8706 - val_categorical_accuracy: 0.8716\n",
      "Epoch 7/25\n",
      "328/328 [==============================] - 88s 267ms/step - loss: 1.0308 - categorical_accuracy: 0.7882 - val_loss: 0.8668 - val_categorical_accuracy: 0.8720\n",
      "Epoch 8/25\n",
      "328/328 [==============================] - 82s 251ms/step - loss: 1.0076 - categorical_accuracy: 0.8040 - val_loss: 0.8569 - val_categorical_accuracy: 0.8827\n",
      "Epoch 9/25\n",
      "328/328 [==============================] - 88s 268ms/step - loss: 1.0041 - categorical_accuracy: 0.8045 - val_loss: 0.8561 - val_categorical_accuracy: 0.8794\n",
      "Epoch 10/25\n",
      "328/328 [==============================] - 83s 252ms/step - loss: 0.9910 - categorical_accuracy: 0.8082 - val_loss: 0.8554 - val_categorical_accuracy: 0.8814\n",
      "Epoch 11/25\n",
      "328/328 [==============================] - 89s 272ms/step - loss: 0.9970 - categorical_accuracy: 0.8095 - val_loss: 0.8542 - val_categorical_accuracy: 0.8817\n",
      "Epoch 12/25\n",
      "328/328 [==============================] - 86s 263ms/step - loss: 0.9913 - categorical_accuracy: 0.8097 - val_loss: 0.8502 - val_categorical_accuracy: 0.8841\n",
      "Epoch 13/25\n",
      "328/328 [==============================] - 87s 264ms/step - loss: 0.9874 - categorical_accuracy: 0.8159 - val_loss: 0.8499 - val_categorical_accuracy: 0.8847\n",
      "Epoch 14/25\n",
      "328/328 [==============================] - 81s 247ms/step - loss: 0.9854 - categorical_accuracy: 0.8162 - val_loss: 0.8446 - val_categorical_accuracy: 0.8873\n",
      "Epoch 15/25\n",
      "328/328 [==============================] - 86s 261ms/step - loss: 0.9842 - categorical_accuracy: 0.8123 - val_loss: 0.8499 - val_categorical_accuracy: 0.8821\n",
      "Epoch 16/25\n",
      "328/328 [==============================] - 80s 245ms/step - loss: 0.9792 - categorical_accuracy: 0.8201 - val_loss: 0.8446 - val_categorical_accuracy: 0.8859\n",
      "Epoch 17/25\n",
      "328/328 [==============================] - 87s 264ms/step - loss: 0.9749 - categorical_accuracy: 0.8242 - val_loss: 0.8453 - val_categorical_accuracy: 0.8856\n",
      "Epoch 18/25\n",
      "328/328 [==============================] - 79s 242ms/step - loss: 0.9751 - categorical_accuracy: 0.8164 - val_loss: 0.8438 - val_categorical_accuracy: 0.8869\n",
      "Epoch 19/25\n",
      "328/328 [==============================] - 80s 245ms/step - loss: 0.9774 - categorical_accuracy: 0.8174 - val_loss: 0.8446 - val_categorical_accuracy: 0.8868\n",
      "Epoch 20/25\n",
      "328/328 [==============================] - 99s 304ms/step - loss: 0.9715 - categorical_accuracy: 0.8232 - val_loss: 0.8450 - val_categorical_accuracy: 0.8863\n",
      "Epoch 21/25\n",
      "328/328 [==============================] - 91s 277ms/step - loss: 0.9759 - categorical_accuracy: 0.8200 - val_loss: 0.8438 - val_categorical_accuracy: 0.8868\n",
      "Epoch 22/25\n",
      "328/328 [==============================] - 83s 253ms/step - loss: 0.9693 - categorical_accuracy: 0.8273 - val_loss: 0.8449 - val_categorical_accuracy: 0.8864\n",
      "Epoch 23/25\n",
      "328/328 [==============================] - 85s 260ms/step - loss: 0.9708 - categorical_accuracy: 0.8277 - val_loss: 0.8461 - val_categorical_accuracy: 0.8858\n",
      "Epoch 24/25\n",
      "328/328 [==============================] - 78s 238ms/step - loss: 0.9672 - categorical_accuracy: 0.8300 - val_loss: 0.8460 - val_categorical_accuracy: 0.8854\n",
      "Epoch 25/25\n",
      "328/328 [==============================] - 81s 248ms/step - loss: 0.9647 - categorical_accuracy: 0.8341 - val_loss: 0.8436 - val_categorical_accuracy: 0.8864\n",
      "\n",
      "FOLD-3\n",
      "\n",
      "Epoch 1/25\n",
      "343/343 [==============================] - 210s 417ms/step - loss: 1.7493 - categorical_accuracy: 0.1131 - val_loss: 1.6441 - val_categorical_accuracy: 0.0797\n",
      "Epoch 2/25\n",
      "343/343 [==============================] - 100s 293ms/step - loss: 1.3138 - categorical_accuracy: 0.5989 - val_loss: 0.9592 - val_categorical_accuracy: 0.8125\n",
      "Epoch 3/25\n",
      "343/343 [==============================] - 96s 280ms/step - loss: 1.1080 - categorical_accuracy: 0.7405 - val_loss: 0.8877 - val_categorical_accuracy: 0.8610\n",
      "Epoch 4/25\n",
      "343/343 [==============================] - 100s 291ms/step - loss: 1.0755 - categorical_accuracy: 0.7560 - val_loss: 0.8677 - val_categorical_accuracy: 0.8736\n",
      "Epoch 5/25\n",
      "343/343 [==============================] - 94s 275ms/step - loss: 1.0405 - categorical_accuracy: 0.7832 - val_loss: 0.8613 - val_categorical_accuracy: 0.8740\n",
      "Epoch 6/25\n",
      "343/343 [==============================] - 85s 248ms/step - loss: 1.0388 - categorical_accuracy: 0.7853 - val_loss: 0.8625 - val_categorical_accuracy: 0.8788\n",
      "Epoch 7/25\n",
      "343/343 [==============================] - 95s 276ms/step - loss: 1.0183 - categorical_accuracy: 0.7971 - val_loss: 0.8423 - val_categorical_accuracy: 0.8870\n",
      "Epoch 8/25\n",
      "343/343 [==============================] - 86s 250ms/step - loss: 1.0105 - categorical_accuracy: 0.7989 - val_loss: 0.8477 - val_categorical_accuracy: 0.8854\n",
      "Epoch 9/25\n",
      "343/343 [==============================] - 108s 317ms/step - loss: 0.9970 - categorical_accuracy: 0.8084 - val_loss: 0.8442 - val_categorical_accuracy: 0.8854\n",
      "Epoch 10/25\n",
      "343/343 [==============================] - 100s 291ms/step - loss: 0.9987 - categorical_accuracy: 0.8069 - val_loss: 0.8371 - val_categorical_accuracy: 0.8904\n",
      "Epoch 11/25\n",
      "343/343 [==============================] - 95s 277ms/step - loss: 0.9927 - categorical_accuracy: 0.8101 - val_loss: 0.8392 - val_categorical_accuracy: 0.8894\n",
      "Epoch 12/25\n",
      "343/343 [==============================] - 86s 251ms/step - loss: 0.9885 - categorical_accuracy: 0.8146 - val_loss: 0.8305 - val_categorical_accuracy: 0.8948\n",
      "Epoch 13/25\n",
      "343/343 [==============================] - 88s 256ms/step - loss: 0.9840 - categorical_accuracy: 0.8160 - val_loss: 0.8272 - val_categorical_accuracy: 0.8980\n",
      "Epoch 14/25\n",
      "343/343 [==============================] - 84s 243ms/step - loss: 0.9740 - categorical_accuracy: 0.8233 - val_loss: 0.8321 - val_categorical_accuracy: 0.8930\n",
      "Epoch 15/25\n",
      "343/343 [==============================] - 97s 283ms/step - loss: 0.9761 - categorical_accuracy: 0.8230 - val_loss: 0.8304 - val_categorical_accuracy: 0.8930\n",
      "Epoch 16/25\n",
      "343/343 [==============================] - 88s 255ms/step - loss: 0.9766 - categorical_accuracy: 0.8206 - val_loss: 0.8294 - val_categorical_accuracy: 0.8938\n",
      "Epoch 17/25\n",
      "343/343 [==============================] - 90s 262ms/step - loss: 0.9687 - categorical_accuracy: 0.8269 - val_loss: 0.8261 - val_categorical_accuracy: 0.8966\n",
      "Epoch 18/25\n",
      "343/343 [==============================] - 86s 251ms/step - loss: 0.9657 - categorical_accuracy: 0.8307 - val_loss: 0.8248 - val_categorical_accuracy: 0.8994\n",
      "Epoch 19/25\n",
      "343/343 [==============================] - 87s 253ms/step - loss: 0.9684 - categorical_accuracy: 0.8263 - val_loss: 0.8246 - val_categorical_accuracy: 0.8980\n",
      "Epoch 20/25\n",
      "343/343 [==============================] - 90s 264ms/step - loss: 0.9659 - categorical_accuracy: 0.8341 - val_loss: 0.8254 - val_categorical_accuracy: 0.8988\n",
      "Epoch 21/25\n",
      "343/343 [==============================] - 87s 254ms/step - loss: 0.9712 - categorical_accuracy: 0.8285 - val_loss: 0.8275 - val_categorical_accuracy: 0.8992\n",
      "Epoch 22/25\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.9652 - categorical_accuracy: 0.8294 - val_loss: 0.8241 - val_categorical_accuracy: 0.9006\n",
      "Epoch 23/25\n",
      "343/343 [==============================] - 87s 253ms/step - loss: 0.9597 - categorical_accuracy: 0.8342 - val_loss: 0.8262 - val_categorical_accuracy: 0.9016\n",
      "Epoch 24/25\n",
      "343/343 [==============================] - 78s 227ms/step - loss: 0.9689 - categorical_accuracy: 0.8291 - val_loss: 0.8248 - val_categorical_accuracy: 0.9008\n",
      "Epoch 25/25\n",
      "343/343 [==============================] - 88s 256ms/step - loss: 0.9632 - categorical_accuracy: 0.8304 - val_loss: 0.8236 - val_categorical_accuracy: 0.9026\n",
      "\n",
      "FOLD-4\n",
      "\n",
      "Epoch 1/25\n",
      "328/328 [==============================] - 219s 414ms/step - loss: 1.5525 - categorical_accuracy: 0.3409 - val_loss: 1.4583 - val_categorical_accuracy: 0.5539\n",
      "Epoch 2/25\n",
      "328/328 [==============================] - 100s 305ms/step - loss: 1.2775 - categorical_accuracy: 0.6181 - val_loss: 0.9603 - val_categorical_accuracy: 0.8165\n",
      "Epoch 3/25\n",
      "328/328 [==============================] - 97s 295ms/step - loss: 1.1006 - categorical_accuracy: 0.7391 - val_loss: 0.9100 - val_categorical_accuracy: 0.8500\n",
      "Epoch 4/25\n",
      "328/328 [==============================] - 97s 297ms/step - loss: 1.0650 - categorical_accuracy: 0.7657 - val_loss: 0.8955 - val_categorical_accuracy: 0.8681\n",
      "Epoch 5/25\n",
      "328/328 [==============================] - 99s 303ms/step - loss: 1.0372 - categorical_accuracy: 0.7891 - val_loss: 0.8578 - val_categorical_accuracy: 0.8797\n",
      "Epoch 6/25\n",
      "328/328 [==============================] - 96s 294ms/step - loss: 1.0340 - categorical_accuracy: 0.7869 - val_loss: 0.8633 - val_categorical_accuracy: 0.8804\n",
      "Epoch 7/25\n",
      "328/328 [==============================] - 99s 302ms/step - loss: 1.0222 - categorical_accuracy: 0.7925 - val_loss: 0.8531 - val_categorical_accuracy: 0.8846\n",
      "Epoch 8/25\n",
      "328/328 [==============================] - 97s 295ms/step - loss: 0.9998 - categorical_accuracy: 0.8035 - val_loss: 0.8434 - val_categorical_accuracy: 0.8921\n",
      "Epoch 9/25\n",
      "328/328 [==============================] - 94s 288ms/step - loss: 1.0043 - categorical_accuracy: 0.8034 - val_loss: 0.8375 - val_categorical_accuracy: 0.8947\n",
      "Epoch 10/25\n",
      "328/328 [==============================] - 96s 293ms/step - loss: 0.9938 - categorical_accuracy: 0.8089 - val_loss: 0.8337 - val_categorical_accuracy: 0.8984\n",
      "Epoch 11/25\n",
      "328/328 [==============================] - 94s 288ms/step - loss: 0.9900 - categorical_accuracy: 0.8119 - val_loss: 0.8327 - val_categorical_accuracy: 0.8957\n",
      "Epoch 12/25\n",
      "328/328 [==============================] - 97s 295ms/step - loss: 0.9813 - categorical_accuracy: 0.8241 - val_loss: 0.8319 - val_categorical_accuracy: 0.9004\n",
      "Epoch 13/25\n",
      "328/328 [==============================] - 94s 286ms/step - loss: 0.9759 - categorical_accuracy: 0.8286 - val_loss: 0.8299 - val_categorical_accuracy: 0.8973\n",
      "Epoch 14/25\n",
      "328/328 [==============================] - 93s 285ms/step - loss: 0.9705 - categorical_accuracy: 0.8366 - val_loss: 0.8287 - val_categorical_accuracy: 0.9007\n",
      "Epoch 15/25\n",
      "328/328 [==============================] - 96s 292ms/step - loss: 0.9659 - categorical_accuracy: 0.8404 - val_loss: 0.8280 - val_categorical_accuracy: 0.9017\n",
      "Epoch 16/25\n",
      "328/328 [==============================] - 93s 285ms/step - loss: 0.9607 - categorical_accuracy: 0.8430 - val_loss: 0.8289 - val_categorical_accuracy: 0.9027\n",
      "Epoch 17/25\n",
      "328/328 [==============================] - 92s 282ms/step - loss: 0.9572 - categorical_accuracy: 0.8455 - val_loss: 0.8281 - val_categorical_accuracy: 0.8999\n",
      "Epoch 18/25\n",
      "328/328 [==============================] - 92s 279ms/step - loss: 0.9583 - categorical_accuracy: 0.8492 - val_loss: 0.8277 - val_categorical_accuracy: 0.8995\n",
      "Epoch 19/25\n",
      "328/328 [==============================] - 94s 286ms/step - loss: 0.9579 - categorical_accuracy: 0.8480 - val_loss: 0.8263 - val_categorical_accuracy: 0.9022\n",
      "Epoch 20/25\n",
      "328/328 [==============================] - 94s 287ms/step - loss: 0.9571 - categorical_accuracy: 0.8459 - val_loss: 0.8272 - val_categorical_accuracy: 0.9004\n",
      "Epoch 21/25\n",
      "328/328 [==============================] - 93s 285ms/step - loss: 0.9519 - categorical_accuracy: 0.8522 - val_loss: 0.8244 - val_categorical_accuracy: 0.9020\n",
      "Epoch 22/25\n",
      "328/328 [==============================] - 93s 282ms/step - loss: 0.9594 - categorical_accuracy: 0.8427 - val_loss: 0.8263 - val_categorical_accuracy: 0.8999\n",
      "Epoch 23/25\n",
      "328/328 [==============================] - 93s 283ms/step - loss: 0.9560 - categorical_accuracy: 0.8476 - val_loss: 0.8262 - val_categorical_accuracy: 0.9004\n",
      "Epoch 24/25\n",
      "328/328 [==============================] - 107s 327ms/step - loss: 0.9564 - categorical_accuracy: 0.8493 - val_loss: 0.8272 - val_categorical_accuracy: 0.8995\n",
      "Epoch 25/25\n",
      "328/328 [==============================] - 96s 292ms/step - loss: 0.9507 - categorical_accuracy: 0.8513 - val_loss: 0.8264 - val_categorical_accuracy: 0.9002\n",
      "\n",
      "FOLD-5\n",
      "\n",
      "Epoch 1/25\n",
      "360/360 [==============================] - 220s 350ms/step - loss: 1.5749 - categorical_accuracy: 0.3203 - val_loss: 1.4498 - val_categorical_accuracy: 0.5680\n",
      "Epoch 2/25\n",
      "360/360 [==============================] - 109s 302ms/step - loss: 1.2771 - categorical_accuracy: 0.6194 - val_loss: 0.9635 - val_categorical_accuracy: 0.8231\n",
      "Epoch 3/25\n",
      "360/360 [==============================] - 110s 306ms/step - loss: 1.1053 - categorical_accuracy: 0.7397 - val_loss: 0.8813 - val_categorical_accuracy: 0.8690\n",
      "Epoch 4/25\n",
      "360/360 [==============================] - 108s 301ms/step - loss: 1.0670 - categorical_accuracy: 0.7650 - val_loss: 0.8969 - val_categorical_accuracy: 0.8632\n",
      "Epoch 5/25\n",
      "360/360 [==============================] - 107s 297ms/step - loss: 1.0449 - categorical_accuracy: 0.7806 - val_loss: 0.8645 - val_categorical_accuracy: 0.8783\n",
      "Epoch 6/25\n",
      "360/360 [==============================] - 108s 300ms/step - loss: 1.0369 - categorical_accuracy: 0.7846 - val_loss: 0.8770 - val_categorical_accuracy: 0.8684\n",
      "Epoch 7/25\n",
      "360/360 [==============================] - 108s 301ms/step - loss: 1.0274 - categorical_accuracy: 0.7905 - val_loss: 0.8534 - val_categorical_accuracy: 0.8866\n",
      "Epoch 8/25\n",
      "360/360 [==============================] - 109s 304ms/step - loss: 1.0159 - categorical_accuracy: 0.7991 - val_loss: 0.8480 - val_categorical_accuracy: 0.8879\n",
      "Epoch 9/25\n",
      "360/360 [==============================] - 109s 304ms/step - loss: 1.0001 - categorical_accuracy: 0.8079 - val_loss: 0.8405 - val_categorical_accuracy: 0.8894\n",
      "Epoch 10/25\n",
      "360/360 [==============================] - 108s 301ms/step - loss: 0.9973 - categorical_accuracy: 0.8086 - val_loss: 0.8403 - val_categorical_accuracy: 0.8952\n",
      "Epoch 11/25\n",
      "360/360 [==============================] - 110s 305ms/step - loss: 0.9889 - categorical_accuracy: 0.8179 - val_loss: 0.8372 - val_categorical_accuracy: 0.8949\n",
      "Epoch 12/25\n",
      "360/360 [==============================] - 107s 298ms/step - loss: 0.9837 - categorical_accuracy: 0.8261 - val_loss: 0.8341 - val_categorical_accuracy: 0.8944\n",
      "Epoch 13/25\n",
      "360/360 [==============================] - 107s 297ms/step - loss: 0.9660 - categorical_accuracy: 0.8360 - val_loss: 0.8287 - val_categorical_accuracy: 0.8989\n",
      "Epoch 14/25\n",
      "360/360 [==============================] - 107s 299ms/step - loss: 0.9748 - categorical_accuracy: 0.8321 - val_loss: 0.8342 - val_categorical_accuracy: 0.8949\n",
      "Epoch 15/25\n",
      "360/360 [==============================] - 107s 297ms/step - loss: 0.9726 - categorical_accuracy: 0.8352 - val_loss: 0.8352 - val_categorical_accuracy: 0.8969\n",
      "Epoch 16/25\n",
      "360/360 [==============================] - 107s 299ms/step - loss: 0.9723 - categorical_accuracy: 0.8369 - val_loss: 0.8292 - val_categorical_accuracy: 0.8987\n",
      "Epoch 17/25\n",
      "360/360 [==============================] - 106s 295ms/step - loss: 0.9668 - categorical_accuracy: 0.8451 - val_loss: 0.8312 - val_categorical_accuracy: 0.8969\n",
      "Epoch 18/25\n",
      "360/360 [==============================] - 111s 307ms/step - loss: 0.9589 - categorical_accuracy: 0.8457 - val_loss: 0.8281 - val_categorical_accuracy: 0.8954\n",
      "Epoch 19/25\n",
      "360/360 [==============================] - 107s 299ms/step - loss: 0.9579 - categorical_accuracy: 0.8464 - val_loss: 0.8280 - val_categorical_accuracy: 0.8979\n",
      "Epoch 20/25\n",
      "360/360 [==============================] - 107s 298ms/step - loss: 0.9623 - categorical_accuracy: 0.8436 - val_loss: 0.8279 - val_categorical_accuracy: 0.8992\n",
      "Epoch 21/25\n",
      "360/360 [==============================] - 106s 295ms/step - loss: 0.9628 - categorical_accuracy: 0.8389 - val_loss: 0.8296 - val_categorical_accuracy: 0.8962\n",
      "Epoch 22/25\n",
      "360/360 [==============================] - 107s 297ms/step - loss: 0.9659 - categorical_accuracy: 0.8424 - val_loss: 0.8289 - val_categorical_accuracy: 0.8962\n",
      "Epoch 23/25\n",
      "360/360 [==============================] - 110s 307ms/step - loss: 0.9574 - categorical_accuracy: 0.8496 - val_loss: 0.8270 - val_categorical_accuracy: 0.8994\n",
      "Epoch 24/25\n",
      "360/360 [==============================] - 108s 299ms/step - loss: 0.9517 - categorical_accuracy: 0.8535 - val_loss: 0.8272 - val_categorical_accuracy: 0.8967\n",
      "Epoch 25/25\n",
      "360/360 [==============================] - 107s 298ms/step - loss: 0.9581 - categorical_accuracy: 0.8480 - val_loss: 0.8282 - val_categorical_accuracy: 0.8979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f, (trn_ind, val_ind) in enumerate(skf.split(TRAINING_FILENAMES)):\n",
    "    print(\"FOLD-{}\".format(f+1))\n",
    "    print()\n",
    "    \n",
    "    TRAIN_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[trn_ind]['TRAINING_FILENAMES'])\n",
    "    VALID_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[val_ind]['TRAINING_FILENAMES'])\n",
    "\n",
    "    train_dataset = get_training_dataset(TRAIN_FILENAMES)\n",
    "    valid_dataset = get_validation_dataset(VALID_FILENAMES)\n",
    "    \n",
    "    NUM_TRAINING_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
    "    NUM_VALID_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "    \n",
    "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "    VALID_STEPS = NUM_VALID_IMAGES // BATCH_SIZE\n",
    "    \n",
    "    CP = tf.keras.callbacks.ModelCheckpoint(\"f5kfold_model-{}.h5\".format(f+1),\n",
    "                                            monitor='loss', verbose=0, save_best_only=True,\n",
    "                                            save_weights_only=False, mode='min', save_freq='epoch')\n",
    "    \n",
    "    model = get_model(f+1)\n",
    "    history = model.fit(train_dataset, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=VALID_STEPS,\n",
    "                        callbacks = [get_lr_callback(BATCH_SIZE), CP])\n",
    "    \n",
    "    print()\n",
    "    del model; z = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 13.056358,
     "end_time": "2021-02-16T09:53:44.315235",
     "exception": false,
     "start_time": "2021-02-16T09:53:31.258877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13284.948329,
   "end_time": "2021-02-16T09:54:02.578150",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-16T06:12:37.629821",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
