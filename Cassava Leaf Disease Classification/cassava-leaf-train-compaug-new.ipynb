{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:52:55.349986Z",
     "iopub.status.busy": "2021-02-10T04:52:55.349178Z",
     "iopub.status.idle": "2021-02-10T04:53:14.315835Z",
     "shell.execute_reply": "2021-02-10T04:53:14.314569Z"
    },
    "papermill": {
     "duration": 18.981737,
     "end_time": "2021-02-10T04:53:14.316105",
     "exception": false,
     "start_time": "2021-02-10T04:52:55.334368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet /kaggle/input/kerasapplications\n",
    "!pip install --quiet /kaggle/input/efficientnet-keras-source-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:14.347746Z",
     "iopub.status.busy": "2021-02-10T04:53:14.347055Z",
     "iopub.status.idle": "2021-02-10T04:53:22.300185Z",
     "shell.execute_reply": "2021-02-10T04:53:22.299569Z"
    },
    "papermill": {
     "duration": 7.971394,
     "end_time": "2021-02-10T04:53:22.300342",
     "exception": false,
     "start_time": "2021-02-10T04:53:14.328948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math, os, random, re\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "import efficientnet.tfkeras as efn\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:22.398726Z",
     "iopub.status.busy": "2021-02-10T04:53:22.397656Z",
     "iopub.status.idle": "2021-02-10T04:53:28.121505Z",
     "shell.execute_reply": "2021-02-10T04:53:28.122034Z"
    },
    "papermill": {
     "duration": 5.810046,
     "end_time": "2021-02-10T04:53:28.122240",
     "exception": false,
     "start_time": "2021-02-10T04:53:22.312194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: grpc://10.0.0.2:8470\n",
      "Number of replicas: 8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.155749Z",
     "iopub.status.busy": "2021-02-10T04:53:28.155037Z",
     "iopub.status.idle": "2021-02-10T04:53:28.658380Z",
     "shell.execute_reply": "2021-02-10T04:53:28.657679Z"
    },
    "papermill": {
     "duration": 0.523455,
     "end_time": "2021-02-10T04:53:28.658531",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.135076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-tfrecords-512x512')\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "EPOCHS = 30\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.714365Z",
     "iopub.status.busy": "2021-02-10T04:53:28.713376Z",
     "iopub.status.idle": "2021-02-10T04:53:28.716185Z",
     "shell.execute_reply": "2021-02-10T04:53:28.716670Z"
    },
    "papermill": {
     "duration": 0.045102,
     "end_time": "2021-02-10T04:53:28.716852",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.671750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform_mat(image, DIM=IMAGE_SIZE[0]):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 \n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "    \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d, [DIM, DIM,3])\n",
    "\n",
    "def dropout(image, DIM=IMAGE_SIZE[0], PROBABILITY = 0.5, CT = 4, SZ = 0.1):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image with CT squares of side size SZ*DIM removed\n",
    "    \n",
    "    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "    if (P==0)|(CT==0)|(SZ==0): return image\n",
    "    \n",
    "    for k in range(CT):\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        # COMPUTE SQUARE \n",
    "        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # DROPOUT IMAGE\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3]) \n",
    "        three = image[ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n",
    "    image = tf.reshape(image,[DIM,DIM,3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.775249Z",
     "iopub.status.busy": "2021-02-10T04:53:28.774477Z",
     "iopub.status.idle": "2021-02-10T04:53:28.777624Z",
     "shell.execute_reply": "2021-02-10T04:53:28.778094Z"
    },
    "papermill": {
     "duration": 0.047833,
     "end_time": "2021-02-10T04:53:28.778333",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.730500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onehot(image,label):\n",
    "    return image,tf.one_hot(label,len(CLASSES))\n",
    "\n",
    "\n",
    "def cutmix(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
    "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j,ya:yb,0:xa,:]\n",
    "        two = image[k,ya:yb,xa:xb,:]\n",
    "        three = image[j,ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def mixup(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with mixup applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
    "        # CHOOSE RANDOM\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n",
    "        # MAKE MIXUP IMAGE\n",
    "        img1 = image[j,]\n",
    "        img2 = image[k,]\n",
    "        imgs.append((1-a)*img1 + a*img2)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "        \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def transform(image,label):\n",
    "    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    SWITCH = 0.5\n",
    "    CUTMIX_PROB = 0.666\n",
    "    MIXUP_PROB = 0.666\n",
    "    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n",
    "    image1 = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        img = transform_mat(image[j,])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        image1.append(img)\n",
    "        \n",
    "    image1 = tf.reshape(tf.stack(image1),(AUG_BATCH,DIM,DIM,3))\n",
    "    image2, label2 = cutmix(image1, label, CUTMIX_PROB)\n",
    "    image3, label3 = mixup(image1, label, MIXUP_PROB)\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n",
    "        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n",
    "        labs.append(P*label2[j,]+(1-P)*label3[j,])\n",
    "    \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image4,label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.816812Z",
     "iopub.status.busy": "2021-02-10T04:53:28.816076Z",
     "iopub.status.idle": "2021-02-10T04:53:28.819667Z",
     "shell.execute_reply": "2021-02-10T04:53:28.819102Z"
    },
    "papermill": {
     "duration": 0.028138,
     "end_time": "2021-02-10T04:53:28.819824",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.791686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0     ###\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.859024Z",
     "iopub.status.busy": "2021-02-10T04:53:28.857898Z",
     "iopub.status.idle": "2021-02-10T04:53:28.862397Z",
     "shell.execute_reply": "2021-02-10T04:53:28.861844Z"
    },
    "papermill": {
     "duration": 0.029085,
     "end_time": "2021-02-10T04:53:28.862548",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.833463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = tf.random.Generator.from_seed(SEED, alg='philox')\n",
    "\n",
    "def data_augment(image, label):\n",
    "    seed = rng.make_seeds(2)[0]\n",
    "    image = tf.image.stateless_random_flip_left_right(image, seed=seed)\n",
    "    image = tf.image.stateless_random_flip_up_down(image, seed=seed)\n",
    "    image = tf.image.stateless_random_brightness(image, 0.3, seed=seed)\n",
    "    image = dropout(image)\n",
    "    return image, label\n",
    "\n",
    "def get_training_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048, seed = SEED)\n",
    "    dataset = dataset.batch(AUG_BATCH)\n",
    "    dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:28.895916Z",
     "iopub.status.busy": "2021-02-10T04:53:28.895244Z",
     "iopub.status.idle": "2021-02-10T04:53:29.085264Z",
     "shell.execute_reply": "2021-02-10T04:53:29.084652Z"
    },
    "papermill": {
     "duration": 0.209086,
     "end_time": "2021-02-10T04:53:29.085424",
     "exception": false,
     "start_time": "2021-02-10T04:53:28.876338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/Id_train*.tfrec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:29.120906Z",
     "iopub.status.busy": "2021-02-10T04:53:29.120235Z",
     "iopub.status.idle": "2021-02-10T04:53:29.123741Z",
     "shell.execute_reply": "2021-02-10T04:53:29.123051Z"
    },
    "papermill": {
     "duration": 0.0245,
     "end_time": "2021-02-10T04:53:29.123890",
     "exception": false,
     "start_time": "2021-02-10T04:53:29.099390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=BATCH_SIZE):\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.00000250 * strategy.num_replicas_in_sync * batch_size\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.92\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:29.162086Z",
     "iopub.status.busy": "2021-02-10T04:53:29.161369Z",
     "iopub.status.idle": "2021-02-10T04:53:55.896730Z",
     "shell.execute_reply": "2021-02-10T04:53:55.896147Z"
    },
    "papermill": {
     "duration": 26.759265,
     "end_time": "2021-02-10T04:53:55.896881",
     "exception": false,
     "start_time": "2021-02-10T04:53:29.137616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
      "71680000/71678424 [==============================] - 2s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b4 (Functional) (None, 16, 16, 1792)      17673816  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 8965      \n",
      "=================================================================\n",
      "Total params: 17,682,781\n",
      "Trainable params: 17,557,581\n",
      "Non-trainable params: 125,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    with strategy.scope():       \n",
    "        input_layer = tf.keras.layers.Input(shape=(512,512,3))\n",
    "        base = efn.EfficientNetB4(input_shape=(512,512,3),weights='noisy-student',include_top=False)\n",
    "        base.trainable = True\n",
    "        \n",
    "        x = base(input_layer)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        output_layer = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=False,\n",
    "            label_smoothing=0.01,  #0.001\n",
    "            name='categorical_crossentropy')\n",
    "        \n",
    "        model.compile(optimizer=opt,loss=loss,metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:55.957333Z",
     "iopub.status.busy": "2021-02-10T04:53:55.956422Z",
     "iopub.status.idle": "2021-02-10T04:53:55.960318Z",
     "shell.execute_reply": "2021-02-10T04:53:55.959640Z"
    },
    "papermill": {
     "duration": 0.036247,
     "end_time": "2021-02-10T04:53:55.960477",
     "exception": false,
     "start_time": "2021-02-10T04:53:55.924230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:56.020586Z",
     "iopub.status.busy": "2021-02-10T04:53:56.019693Z",
     "iopub.status.idle": "2021-02-10T04:53:56.023698Z",
     "shell.execute_reply": "2021-02-10T04:53:56.023121Z"
    },
    "papermill": {
     "duration": 0.035649,
     "end_time": "2021-02-10T04:53:56.023842",
     "exception": false,
     "start_time": "2021-02-10T04:53:55.988193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CP = tf.keras.callbacks.ModelCheckpoint('fcomp_model_new.h5',\n",
    "                                            monitor='categorical_accuracy', verbose=1, save_best_only=True,\n",
    "                                            save_weights_only=False, mode='max', save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T04:53:56.088218Z",
     "iopub.status.busy": "2021-02-10T04:53:56.087180Z",
     "iopub.status.idle": "2021-02-10T05:46:02.010684Z",
     "shell.execute_reply": "2021-02-10T05:46:02.009904Z"
    },
    "papermill": {
     "duration": 3125.960916,
     "end_time": "2021-02-10T05:46:02.010844",
     "exception": false,
     "start_time": "2021-02-10T04:53:56.049928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n",
      "334/334 [==============================] - 202s 322ms/step - loss: 1.6086 - categorical_accuracy: 0.2396\n",
      "\n",
      "Epoch 00001: categorical_accuracy improved from -inf to 0.30820, saving model to fcomp_model_new.h5\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00025680000000000006.\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.9784 - categorical_accuracy: 0.6812\n",
      "\n",
      "Epoch 00002: categorical_accuracy improved from 0.30820 to 0.72137, saving model to fcomp_model_new.h5\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0005126000000000001.\n",
      "334/334 [==============================] - 93s 278ms/step - loss: 0.7673 - categorical_accuracy: 0.7681\n",
      "\n",
      "Epoch 00003: categorical_accuracy improved from 0.72137 to 0.77072, saving model to fcomp_model_new.h5\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0007684000000000001.\n",
      "334/334 [==============================] - 93s 279ms/step - loss: 0.7611 - categorical_accuracy: 0.7740\n",
      "\n",
      "Epoch 00004: categorical_accuracy improved from 0.77072 to 0.77886, saving model to fcomp_model_new.h5\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010242.\n",
      "334/334 [==============================] - 91s 272ms/step - loss: 0.7404 - categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00005: categorical_accuracy did not improve from 0.77886\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00128.\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.7212 - categorical_accuracy: 0.7804\n",
      "\n",
      "Epoch 00006: categorical_accuracy did not improve from 0.77886\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0011776800000000002.\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.7172 - categorical_accuracy: 0.7842\n",
      "\n",
      "Epoch 00007: categorical_accuracy improved from 0.77886 to 0.78962, saving model to fcomp_model_new.h5\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010835456000000002.\n",
      "334/334 [==============================] - 91s 273ms/step - loss: 0.6915 - categorical_accuracy: 0.7991\n",
      "\n",
      "Epoch 00008: categorical_accuracy improved from 0.78962 to 0.79664, saving model to fcomp_model_new.h5\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0009969419520000002.\n",
      "334/334 [==============================] - 92s 275ms/step - loss: 0.6868 - categorical_accuracy: 0.7977\n",
      "\n",
      "Epoch 00009: categorical_accuracy improved from 0.79664 to 0.80113, saving model to fcomp_model_new.h5\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0009172665958400003.\n",
      "334/334 [==============================] - 90s 270ms/step - loss: 0.6728 - categorical_accuracy: 0.7951\n",
      "\n",
      "Epoch 00010: categorical_accuracy improved from 0.80113 to 0.80338, saving model to fcomp_model_new.h5\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0008439652681728003.\n",
      "334/334 [==============================] - 92s 275ms/step - loss: 0.6367 - categorical_accuracy: 0.8168\n",
      "\n",
      "Epoch 00011: categorical_accuracy improved from 0.80338 to 0.81058, saving model to fcomp_model_new.h5\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0007765280467189763.\n",
      "334/334 [==============================] - 96s 286ms/step - loss: 0.6421 - categorical_accuracy: 0.8163\n",
      "\n",
      "Epoch 00012: categorical_accuracy improved from 0.81058 to 0.81802, saving model to fcomp_model_new.h5\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0007144858029814583.\n",
      "334/334 [==============================] - 91s 272ms/step - loss: 0.6399 - categorical_accuracy: 0.8141\n",
      "\n",
      "Epoch 00013: categorical_accuracy improved from 0.81802 to 0.81849, saving model to fcomp_model_new.h5\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0006574069387429416.\n",
      "334/334 [==============================] - 94s 281ms/step - loss: 0.6241 - categorical_accuracy: 0.8185\n",
      "\n",
      "Epoch 00014: categorical_accuracy improved from 0.81849 to 0.81891, saving model to fcomp_model_new.h5\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0006048943836435063.\n",
      "334/334 [==============================] - 94s 282ms/step - loss: 0.6148 - categorical_accuracy: 0.8272\n",
      "\n",
      "Epoch 00015: categorical_accuracy improved from 0.81891 to 0.82911, saving model to fcomp_model_new.h5\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005565828329520258.\n",
      "334/334 [==============================] - 93s 277ms/step - loss: 0.6138 - categorical_accuracy: 0.8260\n",
      "\n",
      "Epoch 00016: categorical_accuracy did not improve from 0.82911\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0005121362063158639.\n",
      "334/334 [==============================] - 92s 276ms/step - loss: 0.5982 - categorical_accuracy: 0.8294\n",
      "\n",
      "Epoch 00017: categorical_accuracy improved from 0.82911 to 0.83196, saving model to fcomp_model_new.h5\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0004712453098105947.\n",
      "334/334 [==============================] - 97s 289ms/step - loss: 0.6029 - categorical_accuracy: 0.8323\n",
      "\n",
      "Epoch 00018: categorical_accuracy improved from 0.83196 to 0.83257, saving model to fcomp_model_new.h5\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0004336256850257472.\n",
      "334/334 [==============================] - 93s 279ms/step - loss: 0.5811 - categorical_accuracy: 0.8387\n",
      "\n",
      "Epoch 00019: categorical_accuracy improved from 0.83257 to 0.84034, saving model to fcomp_model_new.h5\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00039901563022368743.\n",
      "334/334 [==============================] - 94s 282ms/step - loss: 0.5872 - categorical_accuracy: 0.8384\n",
      "\n",
      "Epoch 00020: categorical_accuracy improved from 0.84034 to 0.84239, saving model to fcomp_model_new.h5\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.00036717437980579245.\n",
      "334/334 [==============================] - 96s 289ms/step - loss: 0.5877 - categorical_accuracy: 0.8391\n",
      "\n",
      "Epoch 00021: categorical_accuracy improved from 0.84239 to 0.84244, saving model to fcomp_model_new.h5\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0003378804294213291.\n",
      "334/334 [==============================] - 96s 289ms/step - loss: 0.5693 - categorical_accuracy: 0.8430\n",
      "\n",
      "Epoch 00022: categorical_accuracy improved from 0.84244 to 0.84614, saving model to fcomp_model_new.h5\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00031092999506762275.\n",
      "334/334 [==============================] - 94s 280ms/step - loss: 0.5632 - categorical_accuracy: 0.8521\n",
      "\n",
      "Epoch 00023: categorical_accuracy improved from 0.84614 to 0.85002, saving model to fcomp_model_new.h5\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.00028613559546221293.\n",
      "334/334 [==============================] - 96s 288ms/step - loss: 0.5674 - categorical_accuracy: 0.8502\n",
      "\n",
      "Epoch 00024: categorical_accuracy improved from 0.85002 to 0.85531, saving model to fcomp_model_new.h5\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.00026332474782523593.\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.5634 - categorical_accuracy: 0.8502\n",
      "\n",
      "Epoch 00025: categorical_accuracy did not improve from 0.85531\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00024233876799921702.\n",
      "334/334 [==============================] - 96s 286ms/step - loss: 0.5564 - categorical_accuracy: 0.8499\n",
      "\n",
      "Epoch 00026: categorical_accuracy did not improve from 0.85531\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0002230316665592797.\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.5505 - categorical_accuracy: 0.8576\n",
      "\n",
      "Epoch 00027: categorical_accuracy improved from 0.85531 to 0.85914, saving model to fcomp_model_new.h5\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0002052691332345373.\n",
      "334/334 [==============================] - 93s 278ms/step - loss: 0.5425 - categorical_accuracy: 0.8577\n",
      "\n",
      "Epoch 00028: categorical_accuracy improved from 0.85914 to 0.85998, saving model to fcomp_model_new.h5\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00018892760257577435.\n",
      "334/334 [==============================] - 97s 290ms/step - loss: 0.5404 - categorical_accuracy: 0.8613\n",
      "\n",
      "Epoch 00029: categorical_accuracy improved from 0.85998 to 0.86115, saving model to fcomp_model_new.h5\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0001738933943697124.\n",
      "334/334 [==============================] - 97s 290ms/step - loss: 0.5407 - categorical_accuracy: 0.8645\n",
      "\n",
      "Epoch 00030: categorical_accuracy improved from 0.86115 to 0.86527, saving model to fcomp_model_new.h5\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(get_training_dataset(TRAINING_FILENAMES), \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=EPOCHS,\n",
    "                    #validation_data=valid_dataset,\n",
    "                    #validation_steps=VALID_STEPS,\n",
    "                    callbacks = [get_lr_callback(BATCH_SIZE), CP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T05:46:08.243629Z",
     "iopub.status.busy": "2021-02-10T05:46:08.242933Z",
     "iopub.status.idle": "2021-02-10T05:46:08.647194Z",
     "shell.execute_reply": "2021-02-10T05:46:08.647683Z"
    },
    "papermill": {
     "duration": 3.49548,
     "end_time": "2021-02-10T05:46:08.647865",
     "exception": false,
     "start_time": "2021-02-10T05:46:05.152385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss']].plot()                      #, 'val_loss'\n",
    "history_frame.loc[:, ['categorical_accuracy']].plot();         #,  'val_sparse_categorical_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.072843,
     "end_time": "2021-02-10T05:46:14.892709",
     "exception": false,
     "start_time": "2021-02-10T05:46:11.819866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3213.815251,
   "end_time": "2021-02-10T05:46:23.095401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-10T04:52:49.280150",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
