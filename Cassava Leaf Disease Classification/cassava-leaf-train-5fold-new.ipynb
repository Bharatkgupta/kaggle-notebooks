{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:03:53.937190Z",
     "iopub.status.busy": "2021-02-11T05:03:53.936415Z",
     "iopub.status.idle": "2021-02-11T05:04:12.793991Z",
     "shell.execute_reply": "2021-02-11T05:04:12.794554Z"
    },
    "papermill": {
     "duration": 18.875782,
     "end_time": "2021-02-11T05:04:12.794897",
     "exception": false,
     "start_time": "2021-02-11T05:03:53.919115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet /kaggle/input/kerasapplications\n",
    "!pip install --quiet /kaggle/input/efficientnet-keras-source-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:12.823864Z",
     "iopub.status.busy": "2021-02-11T05:04:12.823179Z",
     "iopub.status.idle": "2021-02-11T05:04:20.555084Z",
     "shell.execute_reply": "2021-02-11T05:04:20.555574Z"
    },
    "papermill": {
     "duration": 7.749359,
     "end_time": "2021-02-11T05:04:20.555799",
     "exception": false,
     "start_time": "2021-02-11T05:04:12.806440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math, os, random, re, gc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "import efficientnet.tfkeras as efn\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:20.587664Z",
     "iopub.status.busy": "2021-02-11T05:04:20.586884Z",
     "iopub.status.idle": "2021-02-11T05:04:25.912820Z",
     "shell.execute_reply": "2021-02-11T05:04:25.913283Z"
    },
    "papermill": {
     "duration": 5.347133,
     "end_time": "2021-02-11T05:04:25.913459",
     "exception": false,
     "start_time": "2021-02-11T05:04:20.566326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:25.939774Z",
     "iopub.status.busy": "2021-02-11T05:04:25.938829Z",
     "iopub.status.idle": "2021-02-11T05:04:26.416537Z",
     "shell.execute_reply": "2021-02-11T05:04:26.415918Z"
    },
    "papermill": {
     "duration": 0.492364,
     "end_time": "2021-02-11T05:04:26.416689",
     "exception": false,
     "start_time": "2021-02-11T05:04:25.924325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-tfrecords-512x512')\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "EPOCHS = 20\n",
    "SEED = 42\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.459825Z",
     "iopub.status.busy": "2021-02-11T05:04:26.459030Z",
     "iopub.status.idle": "2021-02-11T05:04:26.473286Z",
     "shell.execute_reply": "2021-02-11T05:04:26.472695Z"
    },
    "papermill": {
     "duration": 0.045566,
     "end_time": "2021-02-11T05:04:26.473431",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.427865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform_mat(image, DIM=IMAGE_SIZE[0]):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 \n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "    \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d, [DIM, DIM,3])\n",
    "\n",
    "def dropout(image, DIM=IMAGE_SIZE[0], PROBABILITY = 0.5, CT = 4, SZ = 0.1):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image with CT squares of side size SZ*DIM removed\n",
    "    \n",
    "    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "    if (P==0)|(CT==0)|(SZ==0): return image\n",
    "    \n",
    "    for k in range(CT):\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        # COMPUTE SQUARE \n",
    "        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # DROPOUT IMAGE\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3]) \n",
    "        three = image[ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n",
    "    image = tf.reshape(image,[DIM,DIM,3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.517011Z",
     "iopub.status.busy": "2021-02-11T05:04:26.511579Z",
     "iopub.status.idle": "2021-02-11T05:04:26.533336Z",
     "shell.execute_reply": "2021-02-11T05:04:26.532261Z"
    },
    "papermill": {
     "duration": 0.047779,
     "end_time": "2021-02-11T05:04:26.533512",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.485733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onehot(image,label):\n",
    "    return image,tf.one_hot(label,len(CLASSES))\n",
    "\n",
    "\n",
    "def cutmix(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
    "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j,ya:yb,0:xa,:]\n",
    "        two = image[k,ya:yb,xa:xb,:]\n",
    "        three = image[j,ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def mixup(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with mixup applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
    "        # CHOOSE RANDOM\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n",
    "        # MAKE MIXUP IMAGE\n",
    "        img1 = image[j,]\n",
    "        img2 = image[k,]\n",
    "        imgs.append((1-a)*img1 + a*img2)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],CLASSES)\n",
    "            lab2 = tf.one_hot(label[k],CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "        \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image2,label2\n",
    "\n",
    "def transform(image,label):\n",
    "    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    CLASSES = 5\n",
    "    SWITCH = 0.5\n",
    "    CUTMIX_PROB = 0.666\n",
    "    MIXUP_PROB = 0.666\n",
    "    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n",
    "    image1 = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        img = transform_mat(image[j,])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        image1.append(img)\n",
    "        \n",
    "    image1 = tf.reshape(tf.stack(image1),(AUG_BATCH,DIM,DIM,3))\n",
    "    image2, label2 = cutmix(image1, label, CUTMIX_PROB)\n",
    "    image3, label3 = mixup(image1, label, MIXUP_PROB)\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n",
    "        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n",
    "        labs.append(P*label2[j,]+(1-P)*label3[j,])\n",
    "    \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
    "    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
    "    return image4,label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.568922Z",
     "iopub.status.busy": "2021-02-11T05:04:26.568192Z",
     "iopub.status.idle": "2021-02-11T05:04:26.571512Z",
     "shell.execute_reply": "2021-02-11T05:04:26.570971Z"
    },
    "papermill": {
     "duration": 0.026165,
     "end_time": "2021-02-11T05:04:26.571665",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.545500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0     ###\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.604991Z",
     "iopub.status.busy": "2021-02-11T05:04:26.604297Z",
     "iopub.status.idle": "2021-02-11T05:04:26.608350Z",
     "shell.execute_reply": "2021-02-11T05:04:26.607754Z"
    },
    "papermill": {
     "duration": 0.025371,
     "end_time": "2021-02-11T05:04:26.608508",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.583137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.3)\n",
    "    image = dropout(image)\n",
    "    return image, label\n",
    "\n",
    "def get_training_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048, seed = SEED)\n",
    "    dataset = dataset.batch(AUG_BATCH)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(FILENAMES):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.640740Z",
     "iopub.status.busy": "2021-02-11T05:04:26.639669Z",
     "iopub.status.idle": "2021-02-11T05:04:26.642993Z",
     "shell.execute_reply": "2021-02-11T05:04:26.642439Z"
    },
    "papermill": {
     "duration": 0.022789,
     "end_time": "2021-02-11T05:04:26.643151",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.620362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=BATCH_SIZE):\n",
    "    lr_start   = 0.0000001\n",
    "    lr_max     = 0.000000250 * strategy.num_replicas_in_sync * batch_size\n",
    "    lr_min     = 0.0000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.84\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:26.677183Z",
     "iopub.status.busy": "2021-02-11T05:04:26.675378Z",
     "iopub.status.idle": "2021-02-11T05:04:52.104084Z",
     "shell.execute_reply": "2021-02-11T05:04:52.105055Z"
    },
    "papermill": {
     "duration": 25.450459,
     "end_time": "2021-02-11T05:04:52.105318",
     "exception": false,
     "start_time": "2021-02-11T05:04:26.654859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
      "71680000/71678424 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b4 (Functional) (None, 16, 16, 1792)      17673816  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 8965      \n",
      "=================================================================\n",
      "Total params: 17,682,781\n",
      "Trainable params: 17,432,381\n",
      "Non-trainable params: 250,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    with strategy.scope():       \n",
    "        input_layer = tf.keras.layers.Input(shape=(512,512,3))\n",
    "        base = efn.EfficientNetB4(input_shape=(512,512,3),weights='noisy-student',include_top=False)\n",
    "        base.trainable = True\n",
    "        \n",
    "        for layer in base.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable =  False\n",
    "        \n",
    "        x = base(input_layer)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        output_layer = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=False,\n",
    "            label_smoothing=0.1,  #0.001\n",
    "            name='categorical_crossentropy')\n",
    "        \n",
    "        model.compile(optimizer=opt,loss=loss,metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:52.149506Z",
     "iopub.status.busy": "2021-02-11T05:04:52.148826Z",
     "iopub.status.idle": "2021-02-11T05:04:52.252229Z",
     "shell.execute_reply": "2021-02-11T05:04:52.251505Z"
    },
    "papermill": {
     "duration": 0.127807,
     "end_time": "2021-02-11T05:04:52.252372",
     "exception": false,
     "start_time": "2021-02-11T05:04:52.124565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/Id_train*.tfrec\")\n",
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T05:04:52.299165Z",
     "iopub.status.busy": "2021-02-11T05:04:52.298275Z",
     "iopub.status.idle": "2021-02-11T07:33:56.077051Z",
     "shell.execute_reply": "2021-02-11T07:33:56.076348Z"
    },
    "papermill": {
     "duration": 8943.806061,
     "end_time": "2021-02-11T07:33:56.077261",
     "exception": false,
     "start_time": "2021-02-11T05:04:52.271200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD-1\n",
      "\n",
      "Epoch 1/20\n",
      "267/267 [==============================] - 180s 427ms/step - loss: 1.6691 - categorical_accuracy: 0.1541 - val_loss: 1.5673 - val_categorical_accuracy: 0.2779\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 87s 325ms/step - loss: 1.1924 - categorical_accuracy: 0.6241 - val_loss: 0.7787 - val_categorical_accuracy: 0.8170\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 79s 294ms/step - loss: 0.9531 - categorical_accuracy: 0.7464 - val_loss: 0.6976 - val_categorical_accuracy: 0.8494\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 88s 328ms/step - loss: 0.9091 - categorical_accuracy: 0.7840 - val_loss: 0.6569 - val_categorical_accuracy: 0.8774\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 74s 279ms/step - loss: 0.8813 - categorical_accuracy: 0.7844 - val_loss: 0.6533 - val_categorical_accuracy: 0.8762\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 88s 330ms/step - loss: 0.8568 - categorical_accuracy: 0.8001 - val_loss: 0.6478 - val_categorical_accuracy: 0.8809\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.8438 - categorical_accuracy: 0.8118 - val_loss: 0.6279 - val_categorical_accuracy: 0.8873\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 70s 263ms/step - loss: 0.8341 - categorical_accuracy: 0.8133 - val_loss: 0.6309 - val_categorical_accuracy: 0.8864\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 88s 330ms/step - loss: 0.8214 - categorical_accuracy: 0.8206 - val_loss: 0.6195 - val_categorical_accuracy: 0.8935\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 70s 263ms/step - loss: 0.8174 - categorical_accuracy: 0.8242 - val_loss: 0.6117 - val_categorical_accuracy: 0.8965\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 71s 266ms/step - loss: 0.8039 - categorical_accuracy: 0.8297 - val_loss: 0.6079 - val_categorical_accuracy: 0.8991\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 87s 327ms/step - loss: 0.7990 - categorical_accuracy: 0.8266 - val_loss: 0.6116 - val_categorical_accuracy: 0.8944\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 74s 278ms/step - loss: 0.7938 - categorical_accuracy: 0.8332 - val_loss: 0.6029 - val_categorical_accuracy: 0.8973\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 76s 284ms/step - loss: 0.7907 - categorical_accuracy: 0.8371 - val_loss: 0.6033 - val_categorical_accuracy: 0.8958\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 94s 352ms/step - loss: 0.7829 - categorical_accuracy: 0.8387 - val_loss: 0.6006 - val_categorical_accuracy: 0.8975\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 75s 281ms/step - loss: 0.7911 - categorical_accuracy: 0.8346 - val_loss: 0.6006 - val_categorical_accuracy: 0.9006\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 77s 287ms/step - loss: 0.7831 - categorical_accuracy: 0.8403 - val_loss: 0.5980 - val_categorical_accuracy: 0.8999\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 72s 271ms/step - loss: 0.7885 - categorical_accuracy: 0.8354 - val_loss: 0.6008 - val_categorical_accuracy: 0.8973\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 67s 250ms/step - loss: 0.7757 - categorical_accuracy: 0.8428 - val_loss: 0.6009 - val_categorical_accuracy: 0.8949\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 76s 285ms/step - loss: 0.7753 - categorical_accuracy: 0.8430 - val_loss: 0.6012 - val_categorical_accuracy: 0.8980\n",
      "FOLD-2\n",
      "\n",
      "Epoch 1/20\n",
      "267/267 [==============================] - 186s 438ms/step - loss: 1.7071 - categorical_accuracy: 0.1363 - val_loss: 1.4843 - val_categorical_accuracy: 0.5296\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 94s 352ms/step - loss: 1.2051 - categorical_accuracy: 0.6155 - val_loss: 0.7741 - val_categorical_accuracy: 0.8170\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 88s 330ms/step - loss: 0.9458 - categorical_accuracy: 0.7493 - val_loss: 0.6733 - val_categorical_accuracy: 0.8651\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 81s 303ms/step - loss: 0.9020 - categorical_accuracy: 0.7771 - val_loss: 0.6521 - val_categorical_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 81s 305ms/step - loss: 0.8788 - categorical_accuracy: 0.7939 - val_loss: 0.6475 - val_categorical_accuracy: 0.8705\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 74s 278ms/step - loss: 0.8718 - categorical_accuracy: 0.7895 - val_loss: 0.6457 - val_categorical_accuracy: 0.8797\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 71s 265ms/step - loss: 0.8623 - categorical_accuracy: 0.8007 - val_loss: 0.6344 - val_categorical_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 87s 327ms/step - loss: 0.8351 - categorical_accuracy: 0.8156 - val_loss: 0.6368 - val_categorical_accuracy: 0.8819\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 82s 307ms/step - loss: 0.8333 - categorical_accuracy: 0.8117 - val_loss: 0.6466 - val_categorical_accuracy: 0.8812\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 89s 332ms/step - loss: 0.8138 - categorical_accuracy: 0.8243 - val_loss: 0.6232 - val_categorical_accuracy: 0.8849\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 71s 265ms/step - loss: 0.8013 - categorical_accuracy: 0.8274 - val_loss: 0.6166 - val_categorical_accuracy: 0.8887\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 74s 277ms/step - loss: 0.7949 - categorical_accuracy: 0.8341 - val_loss: 0.6293 - val_categorical_accuracy: 0.8845\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 100s 374ms/step - loss: 0.8012 - categorical_accuracy: 0.8297 - val_loss: 0.6199 - val_categorical_accuracy: 0.8913\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 74s 276ms/step - loss: 0.7991 - categorical_accuracy: 0.8264 - val_loss: 0.6165 - val_categorical_accuracy: 0.8944\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 96s 358ms/step - loss: 0.7928 - categorical_accuracy: 0.8406 - val_loss: 0.6161 - val_categorical_accuracy: 0.8930\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 79s 297ms/step - loss: 0.7956 - categorical_accuracy: 0.8255 - val_loss: 0.6169 - val_categorical_accuracy: 0.8942\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 98s 369ms/step - loss: 0.7853 - categorical_accuracy: 0.8394 - val_loss: 0.6182 - val_categorical_accuracy: 0.8916\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 79s 296ms/step - loss: 0.7784 - categorical_accuracy: 0.8401 - val_loss: 0.6144 - val_categorical_accuracy: 0.8928\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 97s 362ms/step - loss: 0.7870 - categorical_accuracy: 0.8356 - val_loss: 0.6149 - val_categorical_accuracy: 0.8930\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 81s 301ms/step - loss: 0.7760 - categorical_accuracy: 0.8439 - val_loss: 0.6193 - val_categorical_accuracy: 0.8930\n",
      "FOLD-3\n",
      "\n",
      "Epoch 1/20\n",
      "267/267 [==============================] - 184s 429ms/step - loss: 1.6040 - categorical_accuracy: 0.2272 - val_loss: 1.5851 - val_categorical_accuracy: 0.2299\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 89s 336ms/step - loss: 1.1649 - categorical_accuracy: 0.6368 - val_loss: 0.7446 - val_categorical_accuracy: 0.8345\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 73s 275ms/step - loss: 0.9475 - categorical_accuracy: 0.7633 - val_loss: 0.6860 - val_categorical_accuracy: 0.8598\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 89s 333ms/step - loss: 0.9058 - categorical_accuracy: 0.7784 - val_loss: 0.6521 - val_categorical_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 73s 272ms/step - loss: 0.8641 - categorical_accuracy: 0.8015 - val_loss: 0.6449 - val_categorical_accuracy: 0.8809\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 81s 302ms/step - loss: 0.8670 - categorical_accuracy: 0.7979 - val_loss: 0.6494 - val_categorical_accuracy: 0.8781\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 74s 279ms/step - loss: 0.8414 - categorical_accuracy: 0.8117 - val_loss: 0.6259 - val_categorical_accuracy: 0.8868\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 71s 268ms/step - loss: 0.8302 - categorical_accuracy: 0.8176 - val_loss: 0.6344 - val_categorical_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 86s 323ms/step - loss: 0.8110 - categorical_accuracy: 0.8203 - val_loss: 0.6264 - val_categorical_accuracy: 0.8885\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 71s 267ms/step - loss: 0.8195 - categorical_accuracy: 0.8210 - val_loss: 0.6206 - val_categorical_accuracy: 0.8897\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 69s 260ms/step - loss: 0.8123 - categorical_accuracy: 0.8238 - val_loss: 0.6160 - val_categorical_accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 80s 299ms/step - loss: 0.7957 - categorical_accuracy: 0.8352 - val_loss: 0.6145 - val_categorical_accuracy: 0.8923\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 75s 280ms/step - loss: 0.7985 - categorical_accuracy: 0.8334 - val_loss: 0.6184 - val_categorical_accuracy: 0.8899\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 78s 291ms/step - loss: 0.7867 - categorical_accuracy: 0.8380 - val_loss: 0.6145 - val_categorical_accuracy: 0.8923\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 86s 324ms/step - loss: 0.7867 - categorical_accuracy: 0.8370 - val_loss: 0.6108 - val_categorical_accuracy: 0.8954\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 69s 258ms/step - loss: 0.7785 - categorical_accuracy: 0.8408 - val_loss: 0.6110 - val_categorical_accuracy: 0.8970\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 67s 251ms/step - loss: 0.7730 - categorical_accuracy: 0.8446 - val_loss: 0.6115 - val_categorical_accuracy: 0.8937\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 84s 315ms/step - loss: 0.7804 - categorical_accuracy: 0.8428 - val_loss: 0.6085 - val_categorical_accuracy: 0.8975\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 132s 497ms/step - loss: 0.7827 - categorical_accuracy: 0.8405 - val_loss: 0.6119 - val_categorical_accuracy: 0.8944\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 75s 282ms/step - loss: 0.7672 - categorical_accuracy: 0.8506 - val_loss: 0.6108 - val_categorical_accuracy: 0.8965\n",
      "FOLD-4\n",
      "\n",
      "Epoch 1/20\n",
      "267/267 [==============================] - 184s 431ms/step - loss: 1.4976 - categorical_accuracy: 0.4492 - val_loss: 1.5009 - val_categorical_accuracy: 0.5069\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 88s 329ms/step - loss: 1.1714 - categorical_accuracy: 0.6356 - val_loss: 0.7764 - val_categorical_accuracy: 0.8284\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 80s 300ms/step - loss: 0.9516 - categorical_accuracy: 0.7496 - val_loss: 0.6719 - val_categorical_accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 90s 336ms/step - loss: 0.8965 - categorical_accuracy: 0.7875 - val_loss: 0.6579 - val_categorical_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 72s 268ms/step - loss: 0.8869 - categorical_accuracy: 0.7923 - val_loss: 0.6516 - val_categorical_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 90s 336ms/step - loss: 0.8670 - categorical_accuracy: 0.7995 - val_loss: 0.6360 - val_categorical_accuracy: 0.8835\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 78s 294ms/step - loss: 0.8471 - categorical_accuracy: 0.8052 - val_loss: 0.6396 - val_categorical_accuracy: 0.8767\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 85s 320ms/step - loss: 0.8420 - categorical_accuracy: 0.8098 - val_loss: 0.6177 - val_categorical_accuracy: 0.8949\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 70s 261ms/step - loss: 0.8181 - categorical_accuracy: 0.8224 - val_loss: 0.6201 - val_categorical_accuracy: 0.8925\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 75s 282ms/step - loss: 0.8192 - categorical_accuracy: 0.8145 - val_loss: 0.6115 - val_categorical_accuracy: 0.8951\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 79s 295ms/step - loss: 0.8068 - categorical_accuracy: 0.8221 - val_loss: 0.6076 - val_categorical_accuracy: 0.8942\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 71s 264ms/step - loss: 0.8073 - categorical_accuracy: 0.8210 - val_loss: 0.6040 - val_categorical_accuracy: 0.8958\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 68s 253ms/step - loss: 0.7993 - categorical_accuracy: 0.8314 - val_loss: 0.6034 - val_categorical_accuracy: 0.8994\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 68s 255ms/step - loss: 0.8026 - categorical_accuracy: 0.8343 - val_loss: 0.6068 - val_categorical_accuracy: 0.8944\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 88s 329ms/step - loss: 0.7944 - categorical_accuracy: 0.8280 - val_loss: 0.5995 - val_categorical_accuracy: 0.8968\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 73s 274ms/step - loss: 0.7879 - categorical_accuracy: 0.8335 - val_loss: 0.6017 - val_categorical_accuracy: 0.8970\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 74s 277ms/step - loss: 0.7830 - categorical_accuracy: 0.8405 - val_loss: 0.6037 - val_categorical_accuracy: 0.8968\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 82s 306ms/step - loss: 0.7843 - categorical_accuracy: 0.8390 - val_loss: 0.6006 - val_categorical_accuracy: 0.8984\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 72s 269ms/step - loss: 0.7765 - categorical_accuracy: 0.8389 - val_loss: 0.6003 - val_categorical_accuracy: 0.8994\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 65s 244ms/step - loss: 0.7754 - categorical_accuracy: 0.8446 - val_loss: 0.6025 - val_categorical_accuracy: 0.8989\n",
      "FOLD-5\n",
      "\n",
      "Epoch 1/20\n",
      "267/267 [==============================] - 177s 408ms/step - loss: 1.7862 - categorical_accuracy: 0.1188 - val_loss: 1.6001 - val_categorical_accuracy: 0.2431\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 84s 315ms/step - loss: 1.2088 - categorical_accuracy: 0.6141 - val_loss: 0.8189 - val_categorical_accuracy: 0.8016\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 79s 295ms/step - loss: 0.9617 - categorical_accuracy: 0.7447 - val_loss: 0.6959 - val_categorical_accuracy: 0.8501\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 79s 296ms/step - loss: 0.8959 - categorical_accuracy: 0.7851 - val_loss: 0.6646 - val_categorical_accuracy: 0.8677\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 71s 268ms/step - loss: 0.8881 - categorical_accuracy: 0.7857 - val_loss: 0.6671 - val_categorical_accuracy: 0.8724\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 67s 250ms/step - loss: 0.8643 - categorical_accuracy: 0.7993 - val_loss: 0.6535 - val_categorical_accuracy: 0.8748\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.8605 - categorical_accuracy: 0.8022 - val_loss: 0.6401 - val_categorical_accuracy: 0.8819\n",
      "Epoch 8/20\n",
      "267/267 [==============================] - 84s 315ms/step - loss: 0.8462 - categorical_accuracy: 0.8081 - val_loss: 0.6346 - val_categorical_accuracy: 0.8788\n",
      "Epoch 9/20\n",
      "267/267 [==============================] - 73s 272ms/step - loss: 0.8150 - categorical_accuracy: 0.8276 - val_loss: 0.6308 - val_categorical_accuracy: 0.8797\n",
      "Epoch 10/20\n",
      "267/267 [==============================] - 73s 274ms/step - loss: 0.8151 - categorical_accuracy: 0.8233 - val_loss: 0.6333 - val_categorical_accuracy: 0.8786\n",
      "Epoch 11/20\n",
      "267/267 [==============================] - 83s 313ms/step - loss: 0.8043 - categorical_accuracy: 0.8340 - val_loss: 0.6259 - val_categorical_accuracy: 0.8864\n",
      "Epoch 12/20\n",
      "267/267 [==============================] - 68s 254ms/step - loss: 0.8092 - categorical_accuracy: 0.8285 - val_loss: 0.6225 - val_categorical_accuracy: 0.8842\n",
      "Epoch 13/20\n",
      "267/267 [==============================] - 64s 242ms/step - loss: 0.8067 - categorical_accuracy: 0.8307 - val_loss: 0.6209 - val_categorical_accuracy: 0.8864\n",
      "Epoch 14/20\n",
      "267/267 [==============================] - 73s 273ms/step - loss: 0.7885 - categorical_accuracy: 0.8304 - val_loss: 0.6197 - val_categorical_accuracy: 0.8883\n",
      "Epoch 15/20\n",
      "267/267 [==============================] - 74s 276ms/step - loss: 0.7905 - categorical_accuracy: 0.8342 - val_loss: 0.6174 - val_categorical_accuracy: 0.8897\n",
      "Epoch 16/20\n",
      "267/267 [==============================] - 71s 267ms/step - loss: 0.7886 - categorical_accuracy: 0.8365 - val_loss: 0.6137 - val_categorical_accuracy: 0.8894\n",
      "Epoch 17/20\n",
      "267/267 [==============================] - 71s 267ms/step - loss: 0.7712 - categorical_accuracy: 0.8423 - val_loss: 0.6133 - val_categorical_accuracy: 0.8890\n",
      "Epoch 18/20\n",
      "267/267 [==============================] - 64s 239ms/step - loss: 0.7894 - categorical_accuracy: 0.8388 - val_loss: 0.6148 - val_categorical_accuracy: 0.8916\n",
      "Epoch 19/20\n",
      "267/267 [==============================] - 60s 225ms/step - loss: 0.7801 - categorical_accuracy: 0.8397 - val_loss: 0.6107 - val_categorical_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "267/267 [==============================] - 60s 226ms/step - loss: 0.7702 - categorical_accuracy: 0.8465 - val_loss: 0.6116 - val_categorical_accuracy: 0.8890\n"
     ]
    }
   ],
   "source": [
    "for f, (trn_ind, val_ind) in enumerate(skf.split(TRAINING_FILENAMES)):\n",
    "    print(\"FOLD-{}\".format(f+1))\n",
    "    print()\n",
    "    \n",
    "    TRAIN_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[trn_ind]['TRAINING_FILENAMES'])\n",
    "    VALID_FILENAMES = list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[val_ind]['TRAINING_FILENAMES'])\n",
    "\n",
    "    train_dataset = get_training_dataset(TRAIN_FILENAMES)\n",
    "    valid_dataset = get_validation_dataset(VALID_FILENAMES)\n",
    "    \n",
    "    NUM_TRAINING_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
    "    NUM_VALID_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "    \n",
    "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "    VALID_STEPS = NUM_VALID_IMAGES // BATCH_SIZE\n",
    "    \n",
    "    CP = tf.keras.callbacks.ModelCheckpoint(\"f5fold_model-{}.h5\".format(f+1),\n",
    "                                            monitor='val_categorical_accuracy', verbose=0, save_best_only=True,\n",
    "                                            save_weights_only=False, mode='max', save_freq='epoch')\n",
    "    \n",
    "    model = get_model()\n",
    "    history = model.fit(train_dataset, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=VALID_STEPS,\n",
    "                        callbacks = [get_lr_callback(BATCH_SIZE), CP])\n",
    "    \n",
    "    del model; z = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8.240664,
     "end_time": "2021-02-11T07:34:12.647647",
     "exception": false,
     "start_time": "2021-02-11T07:34:04.406983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9037.973168,
   "end_time": "2021-02-11T07:34:25.758241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-11T05:03:47.785073",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
